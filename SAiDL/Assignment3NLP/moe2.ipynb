{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: torch in /home/akshat_gosain/.local/lib/python3.10/site-packages (2.2.1)\n",
      "Requirement already satisfied: triton==2.2.0 in /home/akshat_gosain/.local/lib/python3.10/site-packages (from torch) (2.2.0)\n",
      "Requirement already satisfied: fsspec in /home/akshat_gosain/.local/lib/python3.10/site-packages (from torch) (2024.2.0)\n",
      "Requirement already satisfied: filelock in /home/akshat_gosain/.local/lib/python3.10/site-packages (from torch) (3.13.1)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /home/akshat_gosain/.local/lib/python3.10/site-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /home/akshat_gosain/.local/lib/python3.10/site-packages (from torch) (11.0.2.54)\n",
      "Requirement already satisfied: networkx in /home/akshat_gosain/.local/lib/python3.10/site-packages (from torch) (3.2.1)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /home/akshat_gosain/.local/lib/python3.10/site-packages (from torch) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /home/akshat_gosain/.local/lib/python3.10/site-packages (from torch) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /home/akshat_gosain/.local/lib/python3.10/site-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /home/akshat_gosain/.local/lib/python3.10/site-packages (from torch) (4.9.0)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /home/akshat_gosain/.local/lib/python3.10/site-packages (from torch) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /home/akshat_gosain/.local/lib/python3.10/site-packages (from torch) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in /home/akshat_gosain/.local/lib/python3.10/site-packages (from torch) (2.19.3)\n",
      "Requirement already satisfied: sympy in /home/akshat_gosain/.local/lib/python3.10/site-packages (from torch) (1.12)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /home/akshat_gosain/.local/lib/python3.10/site-packages (from torch) (8.9.2.26)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /home/akshat_gosain/.local/lib/python3.10/site-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /home/akshat_gosain/.local/lib/python3.10/site-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: jinja2 in /home/akshat_gosain/.local/lib/python3.10/site-packages (from torch) (3.1.3)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /home/akshat_gosain/.local/lib/python3.10/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch) (12.3.101)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/akshat_gosain/.local/lib/python3.10/site-packages (from jinja2->torch) (2.1.5)\n",
      "Requirement already satisfied: mpmath>=0.19 in /home/akshat_gosain/.local/lib/python3.10/site-packages (from sympy->torch) (1.3.0)\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting mixture_of_experts\n",
      "  Downloading mixture_of_experts-0.2.3-py3-none-any.whl (6.0 kB)\n",
      "Requirement already satisfied: torch in /home/akshat_gosain/.local/lib/python3.10/site-packages (from mixture_of_experts) (2.2.1)\n",
      "Requirement already satisfied: fsspec in /home/akshat_gosain/.local/lib/python3.10/site-packages (from torch->mixture_of_experts) (2024.2.0)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in /home/akshat_gosain/.local/lib/python3.10/site-packages (from torch->mixture_of_experts) (2.19.3)\n",
      "Requirement already satisfied: triton==2.2.0 in /home/akshat_gosain/.local/lib/python3.10/site-packages (from torch->mixture_of_experts) (2.2.0)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /home/akshat_gosain/.local/lib/python3.10/site-packages (from torch->mixture_of_experts) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /home/akshat_gosain/.local/lib/python3.10/site-packages (from torch->mixture_of_experts) (10.3.2.106)\n",
      "Requirement already satisfied: filelock in /home/akshat_gosain/.local/lib/python3.10/site-packages (from torch->mixture_of_experts) (3.13.1)\n",
      "Requirement already satisfied: networkx in /home/akshat_gosain/.local/lib/python3.10/site-packages (from torch->mixture_of_experts) (3.2.1)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /home/akshat_gosain/.local/lib/python3.10/site-packages (from torch->mixture_of_experts) (12.1.0.106)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /home/akshat_gosain/.local/lib/python3.10/site-packages (from torch->mixture_of_experts) (4.9.0)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /home/akshat_gosain/.local/lib/python3.10/site-packages (from torch->mixture_of_experts) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /home/akshat_gosain/.local/lib/python3.10/site-packages (from torch->mixture_of_experts) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /home/akshat_gosain/.local/lib/python3.10/site-packages (from torch->mixture_of_experts) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /home/akshat_gosain/.local/lib/python3.10/site-packages (from torch->mixture_of_experts) (12.1.105)\n",
      "Requirement already satisfied: sympy in /home/akshat_gosain/.local/lib/python3.10/site-packages (from torch->mixture_of_experts) (1.12)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /home/akshat_gosain/.local/lib/python3.10/site-packages (from torch->mixture_of_experts) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /home/akshat_gosain/.local/lib/python3.10/site-packages (from torch->mixture_of_experts) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /home/akshat_gosain/.local/lib/python3.10/site-packages (from torch->mixture_of_experts) (8.9.2.26)\n",
      "Requirement already satisfied: jinja2 in /home/akshat_gosain/.local/lib/python3.10/site-packages (from torch->mixture_of_experts) (3.1.3)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /home/akshat_gosain/.local/lib/python3.10/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch->mixture_of_experts) (12.3.101)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/akshat_gosain/.local/lib/python3.10/site-packages (from jinja2->torch->mixture_of_experts) (2.1.5)\n",
      "Requirement already satisfied: mpmath>=0.19 in /home/akshat_gosain/.local/lib/python3.10/site-packages (from sympy->torch->mixture_of_experts) (1.3.0)\n",
      "Installing collected packages: mixture_of_experts\n",
      "Successfully installed mixture_of_experts-0.2.3\n",
      "Output shape: torch.Size([4, 1024, 10])\n",
      "Auxiliary loss: 0.014753254130482674\n"
     ]
    }
   ],
   "source": [
    "# Install required packages\n",
    "!pip install torch\n",
    "!pip install mixture_of_experts\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "from torch.autograd import Variable\n",
    "from datasets import load_dataset\n",
    "from transformers import AutoTokenizer\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import urllib.request\n",
    "from torch.optim import Adam\n",
    "from torch.utils.data import DataLoader\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from mixture_of_experts import MoE\n",
    "\n",
    "# Define your Mixture-of-Experts model\n",
    "class MyMoEModel(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim, num_experts):\n",
    "        super(MyMoEModel, self).__init__()\n",
    "        \n",
    "        # LSTM layers\n",
    "        self.lstm1 = nn.LSTM(input_dim, hidden_dim, batch_first=True)\n",
    "        self.lstm2 = nn.LSTM(hidden_dim, hidden_dim, batch_first=True)\n",
    "        \n",
    "        # Mixture-of-Experts layer\n",
    "        self.moe = MoE(\n",
    "            dim=hidden_dim,\n",
    "            num_experts=num_experts,\n",
    "            hidden_dim=hidden_dim * 4,\n",
    "            activation=nn.LeakyReLU,\n",
    "            second_policy_train='random',\n",
    "            second_policy_eval='random',\n",
    "            second_threshold_train=0.2,\n",
    "            second_threshold_eval=0.2,\n",
    "            capacity_factor_train=1.25,\n",
    "            capacity_factor_eval=2.,\n",
    "            loss_coef=1e-2\n",
    "        )\n",
    "        \n",
    "        # Output layer\n",
    "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out, _ = self.lstm1(x)\n",
    "        out, _ = self.lstm2(out)\n",
    "        out, aux_loss = self.moe(out)\n",
    "        output = self.fc(out)\n",
    "        return output, aux_loss\n",
    "\n",
    "# Example usage\n",
    "input_dim = 512\n",
    "hidden_dim = 256\n",
    "output_dim = 10\n",
    "num_experts = 16\n",
    "\n",
    "model = MyMoEModel(input_dim, hidden_dim, output_dim, num_experts)\n",
    "inputs = torch.randn(4, 1024, input_dim)\n",
    "outputs, auxiliary_loss = model(inputs)\n",
    "print(\"Output shape:\", outputs.shape)\n",
    "print(\"Auxiliary loss:\", auxiliary_loss.item())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b96755320fd4fd3825235c2b50597ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/14041 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "ValueError",
     "evalue": "not enough values to unpack (expected 2, got 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/home/akshat_gosain/SAiDL/Assignment3NLP/moe2.ipynb Cell 2\u001b[0m line \u001b[0;36m4\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/home/akshat_gosain/SAiDL/Assignment3NLP/moe2.ipynb#W1sdnNjb2RlLXJlbW90ZQ%3D%3D?line=45'>46</a>\u001b[0m \u001b[39mfor\u001b[39;00m batch \u001b[39min\u001b[39;00m train_data:\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/home/akshat_gosain/SAiDL/Assignment3NLP/moe2.ipynb#W1sdnNjb2RlLXJlbW90ZQ%3D%3D?line=46'>47</a>\u001b[0m     optimizer\u001b[39m.\u001b[39mzero_grad()\n\u001b[0;32m---> <a href='vscode-notebook-cell://wsl%2Bubuntu/home/akshat_gosain/SAiDL/Assignment3NLP/moe2.ipynb#W1sdnNjb2RlLXJlbW90ZQ%3D%3D?line=47'>48</a>\u001b[0m     outputs \u001b[39m=\u001b[39m model(batch[\u001b[39m\"\u001b[39;49m\u001b[39minput_ids\u001b[39;49m\u001b[39m\"\u001b[39;49m], attention_mask\u001b[39m=\u001b[39;49mbatch[\u001b[39m\"\u001b[39;49m\u001b[39mattention_mask\u001b[39;49m\u001b[39m\"\u001b[39;49m], labels\u001b[39m=\u001b[39;49mbatch[\u001b[39m\"\u001b[39;49m\u001b[39mlabels\u001b[39;49m\u001b[39m\"\u001b[39;49m])\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/home/akshat_gosain/SAiDL/Assignment3NLP/moe2.ipynb#W1sdnNjb2RlLXJlbW90ZQ%3D%3D?line=48'>49</a>\u001b[0m     loss \u001b[39m=\u001b[39m outputs\u001b[39m.\u001b[39mloss\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/home/akshat_gosain/SAiDL/Assignment3NLP/moe2.ipynb#W1sdnNjb2RlLXJlbW90ZQ%3D%3D?line=49'>50</a>\u001b[0m     total_loss \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m loss\u001b[39m.\u001b[39mitem()\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1522\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/transformers/models/bert/modeling_bert.py:1758\u001b[0m, in \u001b[0;36mBertForTokenClassification.forward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, labels, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1752\u001b[0m \u001b[39m\u001b[39m\u001b[39mr\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   1753\u001b[0m \u001b[39mlabels (`torch.LongTensor` of shape `(batch_size, sequence_length)`, *optional*):\u001b[39;00m\n\u001b[1;32m   1754\u001b[0m \u001b[39m    Labels for computing the token classification loss. Indices should be in `[0, ..., config.num_labels - 1]`.\u001b[39;00m\n\u001b[1;32m   1755\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   1756\u001b[0m return_dict \u001b[39m=\u001b[39m return_dict \u001b[39mif\u001b[39;00m return_dict \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfig\u001b[39m.\u001b[39muse_return_dict\n\u001b[0;32m-> 1758\u001b[0m outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbert(\n\u001b[1;32m   1759\u001b[0m     input_ids,\n\u001b[1;32m   1760\u001b[0m     attention_mask\u001b[39m=\u001b[39;49mattention_mask,\n\u001b[1;32m   1761\u001b[0m     token_type_ids\u001b[39m=\u001b[39;49mtoken_type_ids,\n\u001b[1;32m   1762\u001b[0m     position_ids\u001b[39m=\u001b[39;49mposition_ids,\n\u001b[1;32m   1763\u001b[0m     head_mask\u001b[39m=\u001b[39;49mhead_mask,\n\u001b[1;32m   1764\u001b[0m     inputs_embeds\u001b[39m=\u001b[39;49minputs_embeds,\n\u001b[1;32m   1765\u001b[0m     output_attentions\u001b[39m=\u001b[39;49moutput_attentions,\n\u001b[1;32m   1766\u001b[0m     output_hidden_states\u001b[39m=\u001b[39;49moutput_hidden_states,\n\u001b[1;32m   1767\u001b[0m     return_dict\u001b[39m=\u001b[39;49mreturn_dict,\n\u001b[1;32m   1768\u001b[0m )\n\u001b[1;32m   1770\u001b[0m sequence_output \u001b[39m=\u001b[39m outputs[\u001b[39m0\u001b[39m]\n\u001b[1;32m   1772\u001b[0m sequence_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdropout(sequence_output)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1522\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/transformers/models/bert/modeling_bert.py:967\u001b[0m, in \u001b[0;36mBertModel.forward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    964\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    965\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mYou have to specify either input_ids or inputs_embeds\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m--> 967\u001b[0m batch_size, seq_length \u001b[39m=\u001b[39m input_shape\n\u001b[1;32m    968\u001b[0m device \u001b[39m=\u001b[39m input_ids\u001b[39m.\u001b[39mdevice \u001b[39mif\u001b[39;00m input_ids \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m inputs_embeds\u001b[39m.\u001b[39mdevice\n\u001b[1;32m    970\u001b[0m \u001b[39m# past_key_values_length\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: not enough values to unpack (expected 2, got 1)"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from transformers import BertTokenizer, BertForTokenClassification\n",
    "from datasets import load_dataset\n",
    "\n",
    "# Load CoNLL-2003 dataset\n",
    "dataset = load_dataset(\"conll2003\")\n",
    "\n",
    "# Initialize BERT tokenizer and model\n",
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-cased\")\n",
    "\n",
    "# Corrected line: Get the number of unique labels\n",
    "import numpy as np\n",
    "\n",
    "# Flatten the list of ner_tags and find the number of unique labels\n",
    "num_labels = len(np.unique(np.concatenate(dataset[\"train\"][\"ner_tags\"])))\n",
    "model = BertForTokenClassification.from_pretrained(\"bert-base-cased\", num_labels=num_labels)\n",
    "\n",
    "\n",
    "# Prepare input data\n",
    "def prepare_input_data(example):\n",
    "    # Join the tokens into a single string for each sentence\n",
    "    sentences = [' '.join(tokens) for tokens in example[\"tokens\"]]\n",
    "    # Tokenize each sentence\n",
    "    input_data = [tokenizer(sentence, truncation=True, padding='max_length') for sentence in sentences]\n",
    "    # Prepare the labels: if a sentence is shorter than the max length, pad it with -100s\n",
    "    labels = [label + [-100]*(tokenizer.model_max_length - len(label)) for label in example[\"ner_tags\"]]\n",
    "    # Extract input_ids and attention_mask from input_data\n",
    "    input_ids = [data['input_ids'] for data in input_data]\n",
    "    attention_mask = [data['attention_mask'] for data in input_data]\n",
    "    return {\"input_ids\": input_ids, \"attention_mask\": attention_mask, \"labels\": labels}\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "train_data = dataset[\"train\"].map(prepare_input_data, batched=True)\n",
    "train_data.set_format(type=\"torch\", columns=[\"input_ids\", \"attention_mask\", \"labels\"])\n",
    "\n",
    "# Fine-tune the model\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-5)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "for epoch in range(3):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for batch in train_data:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(batch[\"input_ids\"], attention_mask=batch[\"attention_mask\"], labels=batch[\"labels\"])\n",
    "        loss = outputs.loss\n",
    "        total_loss += loss.item()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    average_loss = total_loss / len(train_data)\n",
    "    print(f\"Epoch {epoch+1} - Average training loss: {average_loss:.4f}\")\n",
    "\n",
    "# Evaluate the model\n",
    "eval_data = dataset[\"validation\"].map(prepare_input_data, batched=True)\n",
    "eval_data.set_format(type=\"torch\", columns=[\"input_ids\", \"attention_mask\", \"labels\"])\n",
    "\n",
    "model.eval()\n",
    "total_loss = 0\n",
    "with torch.no_grad():\n",
    "    for batch in eval_data:\n",
    "        outputs = model(batch[\"input_ids\"], attention_mask=batch[\"attention_mask\"], labels=batch[\"labels\"])\n",
    "        total_loss += outputs.loss.item()\n",
    "\n",
    "average_loss = total_loss / len(eval_data)\n",
    "print(f\"Average validation loss: {average_loss:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
