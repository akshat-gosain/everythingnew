{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.optim import *\n",
    "from torchvision.datasets import *\n",
    "from torchvision.transforms import *\n",
    "from torch.optim.lr_scheduler import *\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm.auto import tqdm\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision.datasets import CIFAR10\n",
    "from torchvision.transforms import Compose, RandomCrop, RandomHorizontalFlip, RandomRotation, ColorJitter, RandomGrayscale, ToTensor, Normalize\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from torch.optim import Adam\n",
    "from tqdm import tqdm\n",
    "import torch.nn.utils.prune as prune\n",
    "import copy\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the BasicBlock class\n",
    "class BasicBlock(nn.Module):\n",
    "    expansion = 1\n",
    "\n",
    "    def __init__(self, in_planes, planes, stride=1):\n",
    "        super(BasicBlock, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(\n",
    "            in_planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3,\n",
    "                               stride=1, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "\n",
    "        self.shortcut = nn.Sequential()\n",
    "        if stride != 1 or in_planes != self.expansion*planes:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(in_planes, self.expansion*planes,\n",
    "                          kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(self.expansion*planes)\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.bn2(self.conv2(out))\n",
    "        out += self.shortcut(x)\n",
    "        out = F.relu(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the ResNet class\n",
    "class ResNet(nn.Module):\n",
    "    def __init__(self, block, num_blocks, num_classes=10):\n",
    "        super(ResNet, self).__init__()\n",
    "        self.in_planes = 64\n",
    "\n",
    "        self.conv1 = nn.Conv2d(3, 64, kernel_size=3,\n",
    "                               stride=1, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        self.layer1 = self._make_layer(block, 64, num_blocks[0], stride=1)\n",
    "        self.layer2 = self._make_layer(block, 128, num_blocks[1], stride=2)\n",
    "        self.layer3 = self._make_layer(block, 256, num_blocks[2], stride=2)\n",
    "        self.layer4 = self._make_layer(block, 512, num_blocks[3], stride=2)\n",
    "        self.linear = nn.Linear(512*block.expansion, num_classes)\n",
    "\n",
    "    def _make_layer(self, block, planes, num_blocks, stride):\n",
    "        strides = [stride] + [1]*(num_blocks-1)\n",
    "        layers = []\n",
    "        for stride in strides:\n",
    "            layers.append(block(self.in_planes, planes, stride))\n",
    "            self.in_planes = planes * block.expansion\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.layer1(out)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        out = self.layer4(out)\n",
    "        out = F.avg_pool2d(out, 4)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = self.linear(out)\n",
    "        return out\n",
    "\n",
    "# Function to create a ResNet18 model\n",
    "def ResNet18():\n",
    "    return ResNet(BasicBlock, [2, 2, 2, 2])\n",
    "\n",
    "# Create the model and move it to GPU\n",
    "model = ResNet18().cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the data augmentation techniques\n",
    "transforms = {\n",
    "    \"train\": Compose([\n",
    "        RandomCrop(32, padding=4),\n",
    "        RandomHorizontalFlip(),\n",
    "        RandomRotation(15),\n",
    "        ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),\n",
    "        RandomGrayscale(p=0.1),\n",
    "        ToTensor(),\n",
    "        Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "    ]),\n",
    "    \"test\": Compose([\n",
    "        ToTensor(),\n",
    "        Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "    ]),\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "# Load the CIFAR10 dataset\n",
    "dataset = {}\n",
    "for split in [\"train\", \"test\"]:\n",
    "  dataset[split] = CIFAR10(\n",
    "    root=\"data/cifar10\",\n",
    "    train=(split == \"train\"),\n",
    "    download=True,\n",
    "    transform=transforms[split],\n",
    "  )\n",
    "\n",
    "# Create the dataloaders\n",
    "dataloader = {}\n",
    "for split in ['train', 'test']:\n",
    "  dataloader[split] = DataLoader(\n",
    "    dataset[split],\n",
    "    batch_size=128,\n",
    "    shuffle=(split == 'train'),\n",
    "    num_workers=0,\n",
    "    pin_memory=True,\n",
    "  )\n",
    "\n",
    "# Split the training dataset into training and validation sets\n",
    "train_dataset = dataset['train']\n",
    "train_size = int(0.8 * len(train_dataset))\n",
    "val_size = len(train_dataset) - train_size\n",
    "train_dataset, val_dataset = random_split(train_dataset, [train_size, val_size])\n",
    "\n",
    "# Create the dataloaders for the training and validation sets\n",
    "batch_size = 128\n",
    "dataloader = {\n",
    "    'train': DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=0, pin_memory=True),\n",
    "    'val': DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=0, pin_memory=True),\n",
    "    'test': dataloader['test']\n",
    "}\n",
    "\n",
    "# Define the loss function\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Define the optimizer\n",
    "optimizer = Adam(model.parameters(), lr=0.001, weight_decay=0.0005)\n",
    "\n",
    "# Define the learning rate scheduler\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the training function\n",
    "def train(model, dataloader, criterion, optimizer):\n",
    "    model.train()\n",
    "    for inputs, targets in tqdm(dataloader, desc='train', leave=False):\n",
    "        inputs = inputs.cuda()\n",
    "        targets = targets.cuda()\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "# Define the function to calculate the validation loss\n",
    "def calculate_validation_loss(model, dataloader, criterion):\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    for inputs, targets in dataloader:\n",
    "        inputs = inputs.cuda()\n",
    "        targets = targets.cuda()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, targets)\n",
    "        running_loss += loss.item() * inputs.size(0)\n",
    "    return running_loss / len(dataloader.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train:   0%|          | 0/313 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Validation Loss: 1.5496818489074706\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, Validation Loss: 1.2916550008773804\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3, Validation Loss: 1.169266043663025\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4, Validation Loss: 0.9052962705612183\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5, Validation Loss: 0.9673701042175293\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6, Validation Loss: 1.0161370304107666\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7, Validation Loss: 0.8589367448806763\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8, Validation Loss: 0.7567067269325256\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9, Validation Loss: 0.769400033569336\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10, Validation Loss: 0.7611384658813477\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11, Validation Loss: 0.49359549446105955\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12, Validation Loss: 0.466042093706131\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13, Validation Loss: 0.4679991998672485\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14, Validation Loss: 0.44143570194244386\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15, Validation Loss: 0.4402107436180115\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16, Validation Loss: 0.4449911829948425\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17, Validation Loss: 0.43247821769714356\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18, Validation Loss: 0.4179987829208374\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19, Validation Loss: 0.40738549437522886\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20, Validation Loss: 0.41499297065734864\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21, Validation Loss: 0.3875271393299103\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22, Validation Loss: 0.3822109576702118\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23, Validation Loss: 0.38627809662818907\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24, Validation Loss: 0.38701479315757753\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25, Validation Loss: 0.38203621554374695\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26, Validation Loss: 0.38125322699546815\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27, Validation Loss: 0.38001804852485654\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28, Validation Loss: 0.37437315640449526\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29, Validation Loss: 0.3773530518770218\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30, Validation Loss: 0.36595945444107053\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31, Validation Loss: 0.3767201412200928\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 32, Validation Loss: 0.37573688573837283\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 33, Validation Loss: 0.37610849084854125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34, Validation Loss: 0.37715803952217103\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 35, Validation Loss: 0.3781751226902008\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 36, Validation Loss: 0.3654918558120728\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 37, Validation Loss: 0.37575388803482057\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 38, Validation Loss: 0.37582590584754944\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 39, Validation Loss: 0.3613237467765808\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 40, Validation Loss: 0.3701188251256943\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 41, Validation Loss: 0.37009437170028686\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 42, Validation Loss: 0.36998495020866395\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 43, Validation Loss: 0.37187491502761844\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 44, Validation Loss: 0.37249222688674927\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 45, Validation Loss: 0.37200254549980166\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 46, Validation Loss: 0.3814457498550415\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 47, Validation Loss: 0.36698203735351564\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 48, Validation Loss: 0.36941740007400514\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49, Validation Loss: 0.36864945311546327\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50, Validation Loss: 0.36181534967422485\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "min_val_loss = float('inf')\n",
    "patience = 20\n",
    "patience_counter = 0\n",
    "num_epochs = 50\n",
    "for epoch in range(num_epochs):\n",
    "    train(model, dataloader['train'], criterion, optimizer)\n",
    "    val_loss = calculate_validation_loss(model, dataloader['val'], criterion)\n",
    "    print(f'Epoch {epoch+1}, Validation Loss: {val_loss}')\n",
    "    if val_loss < min_val_loss:\n",
    "        min_val_loss = val_loss\n",
    "        patience_counter = 0\n",
    "    else:\n",
    "        patience_counter += 1\n",
    "    if patience_counter >= patience:\n",
    "        print('Early stopping')\n",
    "        break\n",
    "    scheduler.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                     "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 10000 test images: 90.02999877929688%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "@torch.inference_mode()\n",
    "def evaluate(\n",
    "  model: nn.Module,\n",
    "  dataloader: DataLoader,\n",
    "  verbose=True,\n",
    ") -> float:\n",
    "  model.eval()\n",
    "\n",
    "  num_samples = 0\n",
    "  num_correct = 0\n",
    "\n",
    "  for inputs, targets in tqdm(dataloader, desc=\"eval\", leave=False,\n",
    "                              disable=not verbose):\n",
    "    # Move the data from CPU to GPU\n",
    "    inputs = inputs.cuda()\n",
    "    targets = targets.cuda()\n",
    "\n",
    "    # Inference\n",
    "    outputs = model(inputs)\n",
    "\n",
    "    # Convert logits to class indices\n",
    "    outputs = outputs.argmax(dim=1)\n",
    "\n",
    "    # Update metrics\n",
    "    num_samples += targets.size(0)\n",
    "    num_correct += (outputs == targets).sum()\n",
    "\n",
    "  return (num_correct / num_samples * 100).item()\n",
    "\n",
    "accuracy = evaluate(model, dataloader['test'])\n",
    "print(f'Accuracy of the network on the 10000 test images: {accuracy}%')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'my_resnet18_90accuracy_.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize a new model\n",
    "new_to_be_pruned_model = ResNet18().cuda()\n",
    "\n",
    "# Load the weights from the file into the new model\n",
    "new_to_be_pruned_model.load_state_dict(torch.load('my_resnet18_90accuracy_.pth'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, test_loader, device, criterion = None):\n",
    "\n",
    "    model.eval()\n",
    "    model.to(device)\n",
    "\n",
    "    running_loss = 0\n",
    "    running_corrects = 0\n",
    "\n",
    "    for inputs, labels in test_loader:\n",
    "\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        outputs = model(inputs)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "\n",
    "        if criterion is not None:\n",
    "            loss = criterion(outputs, labels).item()\n",
    "        else:\n",
    "            loss = 0\n",
    "\n",
    "        # statistics\n",
    "        running_loss += loss * inputs.size(0)\n",
    "        running_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "    eval_loss = running_loss / len(test_loader.dataset)\n",
    "    eval_accuracy = running_corrects / len(test_loader.dataset)\n",
    "\n",
    "    return eval_loss, eval_accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sparsity(tensor: torch.Tensor) -> float:\n",
    "    \n",
    "    return 1 - float(tensor.count_nonzero()) / tensor.numel()\n",
    "\n",
    "def get_model_sparsity(model: nn.Module) -> float:\n",
    "    \n",
    "    num_nonzeros, num_elements = 0, 0\n",
    "    for param in model.parameters():\n",
    "        num_nonzeros += param.count_nonzero()\n",
    "        num_elements += param.numel()\n",
    "    return 1 - float(num_nonzeros) / num_elements\n",
    "\n",
    "def get_num_parameters(model: nn.Module, count_nonzero_only=False) -> int:\n",
    "    \n",
    "    num_counted_elements = 0\n",
    "    for param in model.parameters():\n",
    "        if count_nonzero_only:\n",
    "            num_counted_elements += param.count_nonzero()\n",
    "        else:\n",
    "            num_counted_elements += param.numel()\n",
    "    return num_counted_elements\n",
    "\n",
    "def get_model_size(model: nn.Module, data_width=32, count_nonzero_only=False) -> int:\n",
    "    \n",
    "    return get_num_parameters(model, count_nonzero_only) * data_width\n",
    "\n",
    "class ThresholdPruning(prune.BasePruningMethod):\n",
    "   \n",
    "    PRUNING_TYPE = \"unstructured\"\n",
    "\n",
    "    def __init__(self, threshold):\n",
    "        self.threshold = threshold\n",
    "\n",
    "    def compute_mask(self, tensor, default_mask):\n",
    "        \n",
    "        return torch.abs(tensor) > self.threshold\n",
    "\n",
    "def compute_global_threshold(model, p = 15):\n",
    "    \n",
    "    # Python3 dict to hold weights of trained model-\n",
    "    model_wts = {}\n",
    "    \n",
    "    for layer, params in model.named_parameters():\n",
    "        model_wts[layer] = params.detach().cpu().numpy()\n",
    "    \n",
    "    # Python3 list to hold absolute magnitude flattened weights-\n",
    "    flattened_wts = []\n",
    "   \n",
    "    for layer in model_wts.keys():\n",
    "        flattened_wts.append(np.abs(model_wts[layer].flatten()))\n",
    "    \n",
    "    # Compute threshold using all weights from model-\n",
    "    threshold = np.percentile(np.concatenate(flattened_wts), p)\n",
    "    # print(f\"threshold for {p}th percentile = {threshold:.4f}\")\n",
    "    \n",
    "    return threshold\n",
    "\n",
    "def compute_final_pruning_rate(pruning_rate, num_iterations):\n",
    "\n",
    "    final_pruning_rate = 1 - (1 - pruning_rate) ** num_iterations\n",
    "\n",
    "    return final_pruning_rate\n",
    "\n",
    "def measure_module_sparsity(module, weight=True, bias=False, use_mask=False):\n",
    "\n",
    "    num_zeros = 0\n",
    "    num_elements = 0\n",
    "\n",
    "    if use_mask == True:\n",
    "        for buffer_name, buffer in module.named_buffers():\n",
    "            if \"weight_mask\" in buffer_name and weight == True:\n",
    "                num_zeros += torch.sum(buffer == 0).item()\n",
    "                num_elements += buffer.nelement()\n",
    "            if \"bias_mask\" in buffer_name and bias == True:\n",
    "                num_zeros += torch.sum(buffer == 0).item()\n",
    "                num_elements += buffer.nelement()\n",
    "    else:\n",
    "        for param_name, param in module.named_parameters():\n",
    "            if \"weight\" in param_name and weight == True:\n",
    "                num_zeros += torch.sum(param == 0).item()\n",
    "                num_elements += param.nelement()\n",
    "            if \"bias\" in param_name and bias == True:\n",
    "                num_zeros += torch.sum(param == 0).item()\n",
    "                num_elements += param.nelement()\n",
    "\n",
    "    sparsity = num_zeros / num_elements\n",
    "\n",
    "    return num_zeros, num_elements, sparsity\n",
    "\n",
    "def measure_global_sparsity(\n",
    "    model, weight = True,\n",
    "    bias = False, conv2d_use_mask = False,\n",
    "    linear_use_mask = False):\n",
    "\n",
    "    num_zeros = 0\n",
    "    num_elements = 0\n",
    "\n",
    "    for module_name, module in model.named_modules():\n",
    "\n",
    "        if isinstance(module, torch.nn.Conv2d):\n",
    "\n",
    "            module_num_zeros, module_num_elements, _ = measure_module_sparsity(\n",
    "                module, weight=weight, bias=bias, use_mask=conv2d_use_mask)\n",
    "            num_zeros += module_num_zeros\n",
    "            num_elements += module_num_elements\n",
    "\n",
    "        elif isinstance(module, torch.nn.Linear):\n",
    "\n",
    "            module_num_zeros, module_num_elements, _ = measure_module_sparsity(\n",
    "                module, weight=weight, bias=bias, use_mask=linear_use_mask)\n",
    "            num_zeros += module_num_zeros\n",
    "            num_elements += module_num_elements\n",
    "\n",
    "    sparsity = num_zeros / num_elements\n",
    "\n",
    "    return num_zeros, num_elements, sparsity\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs=20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fine_tune_train_model(model, train_loader, test_loader, device, l1_regularization_strength = 0,\n",
    "                l2_regularization_strength = 1e-4, learning_rate = 1e-1, num_epochs = num_epochs):\n",
    "\n",
    "    # The training configurations were not carefully selected.\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    model.to(device)\n",
    "\n",
    "    # It seems that SGD optimizer is better than Adam optimizer for ResNet18 training on CIFAR10-\n",
    "    optimizer = torch.optim.SGD(\n",
    "        model.parameters(), lr = learning_rate,\n",
    "        momentum = 0.9, weight_decay = l2_regularization_strength\n",
    "    )\n",
    "    # optimizer = optim.Adam(model.parameters(), lr=learning_rate, betas=(0.9, 0.999), eps=1e-08, weight_decay=0, amsgrad=False)\n",
    "    \n",
    "    # Define learning rate scheduler-\n",
    "    scheduler = torch.optim.lr_scheduler.MultiStepLR(\n",
    "        # optimizer, milestones = [100, 150],\n",
    "        optimizer, milestones = [5, 10],\n",
    "        gamma = 0.1, last_epoch = -1)\n",
    "    # scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=500)\n",
    "    \n",
    "\n",
    "    # Evaluation-\n",
    "    model.eval()\n",
    "    eval_loss, eval_accuracy = evaluate_model(\n",
    "        model = model, test_loader = test_loader,\n",
    "        device = device, criterion = criterion)\n",
    "    \n",
    "    print(f\"Pre fine-tuning: val_loss = {eval_loss:.3f} & val_accuracy = {eval_accuracy * 100:.3f}%\")\n",
    "    # print(\"Epoch: {:03d} Eval Loss: {:.3f} Eval Acc: {:.3f}\".format(0, eval_loss, eval_accuracy))\n",
    "\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "\n",
    "        # Training\n",
    "        model.train()\n",
    "\n",
    "        running_loss = 0\n",
    "        running_corrects = 0\n",
    "\n",
    "        for inputs, labels in train_loader:\n",
    "\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            # zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # forward + backward + optimize\n",
    "            outputs = model(inputs)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            l1_reg = torch.tensor(0.).to(device)\n",
    "            for module in model.modules():\n",
    "                mask = None\n",
    "                weight = None\n",
    "                for name, buffer in module.named_buffers():\n",
    "                    if name == \"weight_mask\":\n",
    "                        mask = buffer\n",
    "                for name, param in module.named_parameters():\n",
    "                    if name == \"weight_orig\":\n",
    "                        weight = param\n",
    "                # We usually only want to introduce sparsity to weights and prune weights.\n",
    "                # Do the same for bias if necessary.\n",
    "                if mask is not None and weight is not None:\n",
    "                    l1_reg += torch.norm(mask * weight, 1)\n",
    "\n",
    "            loss += l1_regularization_strength * l1_reg\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # statistics\n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "            running_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "        train_loss = running_loss / len(train_loader.dataset)\n",
    "        train_accuracy = running_corrects / len(train_loader.dataset)\n",
    "\n",
    "        # Evaluation\n",
    "        model.eval()\n",
    "        eval_loss, eval_accuracy = evaluate_model(\n",
    "            model = model, test_loader = test_loader,\n",
    "            device = device, criterion = criterion)\n",
    "\n",
    "        # Set learning rate scheduler\n",
    "        scheduler.step()\n",
    "        \n",
    "        print(f\"epoch = {epoch + 1} loss = {train_loss:.3f}, accuracy = {train_accuracy * 100:.3f}%, val_loss = {eval_loss:.3f}, val_accuracy = {eval_accuracy * 100:.3f}% & LR: {optimizer.param_groups[0]['lr']:.4f}\")\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def iterative_pruning_finetuning(\n",
    "    model, train_loader, test_loader, device,\n",
    "    learning_rate, l1_regularization_strength,\n",
    "    l2_regularization_strength, learning_rate_decay = 0.1,\n",
    "    conv2d_prune_amount = 0.2, linear_prune_amount = 0.1,\n",
    "    num_iterations = 10, num_epochs_per_iteration = 10,\n",
    "    model_filename_prefix = \"pruned_model\", model_dir = \"saved_models\",\n",
    "    grouped_pruning = False):\n",
    "    \n",
    "    best_val_acc = 0\n",
    "\n",
    "    for i in range(1, num_iterations + 1):\n",
    "\n",
    "        print(\"\\nPruning and Finetuning {}/{}\".format(i, num_iterations))\n",
    "\n",
    "        print(\"Pruning...\")\n",
    "\n",
    "\n",
    "        # NOTE: For global pruning, linear/dense layer can also be pruned!\n",
    "        if grouped_pruning == True:\n",
    "            # grouped_pruning -> Global pruning\n",
    "            parameters_to_prune = []\n",
    "            for module_name, module in model.named_modules():\n",
    "                if isinstance(module, torch.nn.Conv2d):\n",
    "                    parameters_to_prune.append((module, \"weight\"))\n",
    "                elif isinstance(module, torch.nn.Linear):\n",
    "                    parameters_to_prune.append((module, \"weight\"))\n",
    "            \n",
    "            # Use custom absolute magnitude weight based 'global', 'unstructured' and 'iterative' pruning:\n",
    "            \n",
    "            # Compute threshold-\n",
    "            computed_threshold = compute_global_threshold(model, p = pruning_rates[i - 1])\n",
    "            # print(f\"threshold for 20th percentile = {threshold}\")\n",
    "\n",
    "            prune.global_unstructured(\n",
    "                parameters_to_prune,\n",
    "                pruning_method = ThresholdPruning,\n",
    "                threshold = computed_threshold\n",
    "            )\n",
    "        \n",
    "        # layer-wise pruning-\n",
    "        else:\n",
    "            for module_name, module in model.named_modules():\n",
    "                if isinstance(module, torch.nn.Conv2d):\n",
    "                    prune.l1_unstructured(\n",
    "                        module, name = \"weight\",\n",
    "                        amount = conv2d_prune_amount)\n",
    "                elif isinstance(module, torch.nn.Linear):\n",
    "                    prune.l1_unstructured(\n",
    "                        module, name = \"weight\",\n",
    "                        amount = linear_prune_amount)\n",
    "\n",
    "        # Compute validation accuracy just after pruning-\n",
    "        _, eval_accuracy = evaluate_model(\n",
    "            model = model, test_loader = test_loader,\n",
    "            device = device, criterion = None)\n",
    "\n",
    "        # Compute global sparsity-\n",
    "        num_zeros, num_elements, sparsity = measure_global_sparsity(\n",
    "            model, weight = True,\n",
    "            bias = False, conv2d_use_mask = True,\n",
    "            linear_use_mask = False)\n",
    "        \n",
    "        print(f\"Global sparsity = {sparsity * 100:.3f}% & val_accuracy = {eval_accuracy * 100:.3f}%\")\n",
    "        # print(model.conv1._forward_pre_hooks)\n",
    "\n",
    "        print(\"\\nFine-tuning...\")\n",
    "\n",
    "        # train_model(\n",
    "        fine_tuned_model = fine_tune_train_model(\n",
    "            model = model, train_loader = train_loader,\n",
    "            test_loader = test_loader, device = device,\n",
    "            l1_regularization_strength = l1_regularization_strength,\n",
    "            l2_regularization_strength = l2_regularization_strength,\n",
    "            # i -> current pruning round-\n",
    "            # learning_rate = learning_rate * (learning_rate_decay ** i),\n",
    "            learning_rate = 1e-1,\n",
    "            num_epochs = num_epochs_per_iteration)\n",
    "\n",
    "        _, eval_accuracy = evaluate_model(\n",
    "            model=model, test_loader = test_loader,\n",
    "            device = device, criterion = None)\n",
    "\n",
    "        num_zeros, num_elements, sparsity = measure_global_sparsity(\n",
    "            # model,\n",
    "            model, weight = True,\n",
    "            bias = False, conv2d_use_mask = True,\n",
    "            linear_use_mask = False)\n",
    "\n",
    "        print(f\"Post fine-tuning: Global sparsity = {sparsity * 100:.3f}% & val_accuracy = {eval_accuracy * 100:.3f}%\")\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_parameters(model):\n",
    "\n",
    "    for module_name, module in model.named_modules():\n",
    "        if isinstance(module, torch.nn.Conv2d):\n",
    "            try:\n",
    "                prune.remove(module, \"weight\")\n",
    "            except:\n",
    "                pass\n",
    "            try:\n",
    "                prune.remove(module, \"bias\")\n",
    "            except:\n",
    "                pass\n",
    "        elif isinstance(module, torch.nn.Linear):\n",
    "            try:\n",
    "                prune.remove(module, \"weight\")\n",
    "            except:\n",
    "                pass\n",
    "            try:\n",
    "                prune.remove(module, \"bias\")\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_classification_report(model, device, test_loader):\n",
    "\n",
    "    model.eval()\n",
    "    model.to(device)\n",
    "\n",
    "    y_pred = []\n",
    "    y_true = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for data in test_loader:\n",
    "            y_true += data[1].numpy().tolist()\n",
    "            images, _ = data[0].to(device), data[1].to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            y_pred += predicted.cpu().numpy().tolist()\n",
    "\n",
    "    classification_report = sklearn.metrics.classification_report(\n",
    "        y_true = y_true, y_pred = y_pred)\n",
    "\n",
    "    return classification_report\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "\n",
    "def sensitivity_analysis(model, train_loader, test_loader, device, num_epochs):\n",
    "    # Store the original state of the model\n",
    "    original_state_dict = copy.deepcopy(model.state_dict())\n",
    "\n",
    "    # Define the sparsity levels you want to test\n",
    "    sparsity_levels = [0.1, 0.5, 0.9]  # fewer sparsity levels\n",
    "\n",
    "    for name, module in model.named_modules():\n",
    "        if isinstance(module, torch.nn.Conv2d):  # only Conv2d layers\n",
    "            # Store the original state of the layer\n",
    "            original_weights = copy.deepcopy(module.weight.data)\n",
    "\n",
    "            for sparsity in sparsity_levels:\n",
    "                # Prune the layer\n",
    "                threshold = np.percentile(torch.abs(original_weights).cpu().numpy(), sparsity * 100)\n",
    "                pruning_method = ThresholdPruning(threshold)\n",
    "                prune.custom_from_mask(module, name='weight', mask=pruning_method.compute_mask(module.weight, default_mask=None))\n",
    "\n",
    "                # Fine-tune the model\n",
    "                fine_tune_train_model(model, train_loader, test_loader, device, num_epochs=num_epochs)  # fewer epochs\n",
    "\n",
    "                # Evaluate the model\n",
    "                _, accuracy = evaluate_model(model, test_loader, device, criterion=None)\n",
    "\n",
    "                print(f\"Layer: {name}, Sparsity: {sparsity * 100}%, Accuracy: {accuracy}%\")\n",
    "\n",
    "                # Reset the weights of the layer to their original state\n",
    "                module.weight.data = original_weights\n",
    "\n",
    "    # Reset the weights of the model to their original state\n",
    "    model.load_state_dict(original_state_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "def prepare_data_loaders(batch_size=64):\n",
    "    # Define the data transformations\n",
    "    transform = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "    ])\n",
    "\n",
    "    # Load the CIFAR-10 datasets\n",
    "    train_dataset = datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
    "    test_dataset = datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
    "\n",
    "    # Create the data loaders\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    return train_loader, test_loader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "# Load the model\n",
    "model = new_to_be_pruned_model\n",
    "\n",
    "# Prepare your data loaders\n",
    "train_loader, test_loader = prepare_data_loaders()\n",
    "\n",
    "# Specify the device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sensitivity Scan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Pre fine-tuning: val_loss = 0.312 & val_accuracy = 90.030%\n",
      "epoch = 1 loss = 0.782, accuracy = 73.160%, val_loss = 0.593, val_accuracy = 79.990% & LR: 0.1000\n",
      "epoch = 2 loss = 0.489, accuracy = 83.152%, val_loss = 0.613, val_accuracy = 78.940% & LR: 0.1000\n",
      "epoch = 3 loss = 0.391, accuracy = 86.404%, val_loss = 0.578, val_accuracy = 80.740% & LR: 0.1000\n",
      "epoch = 4 loss = 0.321, accuracy = 88.872%, val_loss = 0.522, val_accuracy = 83.080% & LR: 0.1000\n",
      "epoch = 5 loss = 0.273, accuracy = 90.482%, val_loss = 0.523, val_accuracy = 83.000% & LR: 0.0100\n",
      "Layer: conv1, Sparsity: 10.0%, Accuracy: 0.8299999833106995%\n",
      "Pre fine-tuning: val_loss = 0.630 & val_accuracy = 79.490%\n",
      "epoch = 1 loss = 0.238, accuracy = 91.604%, val_loss = 0.828, val_accuracy = 77.270% & LR: 0.1000\n",
      "epoch = 2 loss = 0.209, accuracy = 92.658%, val_loss = 0.483, val_accuracy = 84.480% & LR: 0.1000\n",
      "epoch = 3 loss = 0.174, accuracy = 93.848%, val_loss = 0.546, val_accuracy = 84.190% & LR: 0.1000\n",
      "epoch = 4 loss = 0.161, accuracy = 94.406%, val_loss = 0.636, val_accuracy = 81.300% & LR: 0.1000\n",
      "epoch = 5 loss = 0.145, accuracy = 94.920%, val_loss = 0.550, val_accuracy = 84.430% & LR: 0.0100\n",
      "Layer: conv1, Sparsity: 50.0%, Accuracy: 0.8442999720573425%\n",
      "Pre fine-tuning: val_loss = 1.183 & val_accuracy = 62.500%\n",
      "epoch = 1 loss = 0.159, accuracy = 94.514%, val_loss = 0.556, val_accuracy = 83.180% & LR: 0.1000\n",
      "epoch = 2 loss = 0.129, accuracy = 95.488%, val_loss = 0.643, val_accuracy = 82.340% & LR: 0.1000\n",
      "epoch = 3 loss = 0.118, accuracy = 95.906%, val_loss = 0.562, val_accuracy = 84.520% & LR: 0.1000\n",
      "epoch = 4 loss = 0.120, accuracy = 95.866%, val_loss = 0.774, val_accuracy = 80.150% & LR: 0.1000\n",
      "epoch = 5 loss = 0.100, accuracy = 96.582%, val_loss = 0.572, val_accuracy = 84.750% & LR: 0.0100\n",
      "Layer: conv1, Sparsity: 90.0%, Accuracy: 0.8474999666213989%\n",
      "Pre fine-tuning: val_loss = 0.572 & val_accuracy = 84.760%\n",
      "epoch = 1 loss = 0.099, accuracy = 96.596%, val_loss = 0.629, val_accuracy = 83.610% & LR: 0.1000\n",
      "epoch = 2 loss = 0.103, accuracy = 96.372%, val_loss = 0.634, val_accuracy = 82.790% & LR: 0.1000\n",
      "epoch = 3 loss = 0.095, accuracy = 96.680%, val_loss = 0.736, val_accuracy = 82.500% & LR: 0.1000\n",
      "epoch = 4 loss = 0.096, accuracy = 96.608%, val_loss = 0.613, val_accuracy = 83.500% & LR: 0.1000\n",
      "epoch = 5 loss = 0.095, accuracy = 96.626%, val_loss = 0.569, val_accuracy = 85.420% & LR: 0.0100\n",
      "Layer: layer1.0.conv1, Sparsity: 10.0%, Accuracy: 0.854200005531311%\n",
      "Pre fine-tuning: val_loss = 0.566 & val_accuracy = 85.520%\n",
      "epoch = 1 loss = 0.088, accuracy = 96.972%, val_loss = 0.623, val_accuracy = 84.180% & LR: 0.1000\n",
      "epoch = 2 loss = 0.094, accuracy = 96.718%, val_loss = 0.556, val_accuracy = 85.780% & LR: 0.1000\n",
      "epoch = 3 loss = 0.091, accuracy = 96.844%, val_loss = 0.638, val_accuracy = 83.170% & LR: 0.1000\n",
      "epoch = 4 loss = 0.088, accuracy = 96.974%, val_loss = 0.546, val_accuracy = 85.130% & LR: 0.1000\n",
      "epoch = 5 loss = 0.083, accuracy = 97.192%, val_loss = 0.602, val_accuracy = 83.970% & LR: 0.0100\n",
      "Layer: layer1.0.conv1, Sparsity: 50.0%, Accuracy: 0.8396999835968018%\n",
      "Pre fine-tuning: val_loss = 0.676 & val_accuracy = 82.070%\n",
      "epoch = 1 loss = 0.088, accuracy = 97.016%, val_loss = 0.500, val_accuracy = 86.410% & LR: 0.1000\n",
      "epoch = 2 loss = 0.084, accuracy = 97.176%, val_loss = 0.656, val_accuracy = 83.450% & LR: 0.1000\n",
      "epoch = 3 loss = 0.082, accuracy = 97.220%, val_loss = 0.651, val_accuracy = 83.060% & LR: 0.1000\n",
      "epoch = 4 loss = 0.091, accuracy = 96.816%, val_loss = 0.555, val_accuracy = 85.290% & LR: 0.1000\n",
      "epoch = 5 loss = 0.090, accuracy = 96.856%, val_loss = 0.602, val_accuracy = 83.930% & LR: 0.0100\n",
      "Layer: layer1.0.conv1, Sparsity: 90.0%, Accuracy: 0.8392999768257141%\n",
      "Pre fine-tuning: val_loss = 0.603 & val_accuracy = 83.960%\n",
      "epoch = 1 loss = 0.076, accuracy = 97.342%, val_loss = 0.586, val_accuracy = 84.310% & LR: 0.1000\n",
      "epoch = 2 loss = 0.080, accuracy = 97.232%, val_loss = 0.591, val_accuracy = 84.370% & LR: 0.1000\n",
      "epoch = 3 loss = 0.082, accuracy = 97.128%, val_loss = 0.589, val_accuracy = 84.050% & LR: 0.1000\n",
      "epoch = 4 loss = 0.089, accuracy = 96.838%, val_loss = 0.575, val_accuracy = 85.040% & LR: 0.1000\n",
      "epoch = 5 loss = 0.080, accuracy = 97.312%, val_loss = 0.638, val_accuracy = 83.500% & LR: 0.0100\n",
      "Layer: layer1.0.conv2, Sparsity: 10.0%, Accuracy: 0.8349999785423279%\n",
      "Pre fine-tuning: val_loss = 0.631 & val_accuracy = 83.550%\n",
      "epoch = 1 loss = 0.070, accuracy = 97.626%, val_loss = 0.762, val_accuracy = 81.490% & LR: 0.1000\n",
      "epoch = 2 loss = 0.083, accuracy = 97.182%, val_loss = 0.678, val_accuracy = 82.210% & LR: 0.1000\n",
      "epoch = 3 loss = 0.082, accuracy = 97.146%, val_loss = 0.680, val_accuracy = 82.800% & LR: 0.1000\n",
      "epoch = 4 loss = 0.081, accuracy = 97.166%, val_loss = 0.689, val_accuracy = 82.670% & LR: 0.1000\n",
      "epoch = 5 loss = 0.077, accuracy = 97.418%, val_loss = 0.658, val_accuracy = 82.650% & LR: 0.0100\n",
      "Layer: layer1.0.conv2, Sparsity: 50.0%, Accuracy: 0.8264999985694885%\n",
      "Pre fine-tuning: val_loss = 0.710 & val_accuracy = 81.010%\n",
      "epoch = 1 loss = 0.072, accuracy = 97.578%, val_loss = 0.619, val_accuracy = 84.240% & LR: 0.1000\n",
      "epoch = 2 loss = 0.084, accuracy = 97.102%, val_loss = 0.737, val_accuracy = 82.190% & LR: 0.1000\n",
      "epoch = 3 loss = 0.079, accuracy = 97.244%, val_loss = 0.589, val_accuracy = 84.840% & LR: 0.1000\n",
      "epoch = 4 loss = 0.082, accuracy = 97.164%, val_loss = 0.678, val_accuracy = 83.100% & LR: 0.1000\n",
      "epoch = 5 loss = 0.076, accuracy = 97.522%, val_loss = 0.528, val_accuracy = 86.040% & LR: 0.0100\n",
      "Layer: layer1.0.conv2, Sparsity: 90.0%, Accuracy: 0.8603999614715576%\n",
      "Pre fine-tuning: val_loss = 0.528 & val_accuracy = 86.050%\n",
      "epoch = 1 loss = 0.070, accuracy = 97.532%, val_loss = 0.534, val_accuracy = 85.800% & LR: 0.1000\n",
      "epoch = 2 loss = 0.082, accuracy = 97.194%, val_loss = 0.750, val_accuracy = 80.680% & LR: 0.1000\n",
      "epoch = 3 loss = 0.074, accuracy = 97.564%, val_loss = 0.581, val_accuracy = 85.290% & LR: 0.1000\n",
      "epoch = 4 loss = 0.079, accuracy = 97.268%, val_loss = 0.684, val_accuracy = 83.050% & LR: 0.1000\n",
      "epoch = 5 loss = 0.082, accuracy = 97.216%, val_loss = 0.637, val_accuracy = 84.220% & LR: 0.0100\n",
      "Layer: layer1.1.conv1, Sparsity: 10.0%, Accuracy: 0.842199981212616%\n",
      "Pre fine-tuning: val_loss = 0.634 & val_accuracy = 84.260%\n",
      "epoch = 1 loss = 0.071, accuracy = 97.558%, val_loss = 0.556, val_accuracy = 85.060% & LR: 0.1000\n",
      "epoch = 2 loss = 0.073, accuracy = 97.570%, val_loss = 0.587, val_accuracy = 85.170% & LR: 0.1000\n",
      "epoch = 3 loss = 0.072, accuracy = 97.506%, val_loss = 0.641, val_accuracy = 83.230% & LR: 0.1000\n",
      "epoch = 4 loss = 0.071, accuracy = 97.566%, val_loss = 0.664, val_accuracy = 83.810% & LR: 0.1000\n",
      "epoch = 5 loss = 0.080, accuracy = 97.226%, val_loss = 0.687, val_accuracy = 82.920% & LR: 0.0100\n",
      "Layer: layer1.1.conv1, Sparsity: 50.0%, Accuracy: 0.8291999697685242%\n",
      "Pre fine-tuning: val_loss = 0.817 & val_accuracy = 79.150%\n",
      "epoch = 1 loss = 0.073, accuracy = 97.530%, val_loss = 0.533, val_accuracy = 85.410% & LR: 0.1000\n",
      "epoch = 2 loss = 0.069, accuracy = 97.636%, val_loss = 0.652, val_accuracy = 83.410% & LR: 0.1000\n",
      "epoch = 3 loss = 0.071, accuracy = 97.508%, val_loss = 0.617, val_accuracy = 84.290% & LR: 0.1000\n",
      "epoch = 4 loss = 0.081, accuracy = 97.176%, val_loss = 0.740, val_accuracy = 81.450% & LR: 0.1000\n",
      "epoch = 5 loss = 0.073, accuracy = 97.540%, val_loss = 0.677, val_accuracy = 83.480% & LR: 0.0100\n",
      "Layer: layer1.1.conv1, Sparsity: 90.0%, Accuracy: 0.8348000049591064%\n",
      "Pre fine-tuning: val_loss = 0.677 & val_accuracy = 83.490%\n",
      "epoch = 1 loss = 0.063, accuracy = 97.936%, val_loss = 0.746, val_accuracy = 81.610% & LR: 0.1000\n",
      "epoch = 2 loss = 0.080, accuracy = 97.210%, val_loss = 0.592, val_accuracy = 84.850% & LR: 0.1000\n",
      "epoch = 3 loss = 0.077, accuracy = 97.422%, val_loss = 0.707, val_accuracy = 83.110% & LR: 0.1000\n",
      "epoch = 4 loss = 0.083, accuracy = 97.170%, val_loss = 0.589, val_accuracy = 84.620% & LR: 0.1000\n",
      "epoch = 5 loss = 0.071, accuracy = 97.524%, val_loss = 0.584, val_accuracy = 85.360% & LR: 0.0100\n",
      "Layer: layer1.1.conv2, Sparsity: 10.0%, Accuracy: 0.8535999655723572%\n",
      "Pre fine-tuning: val_loss = 0.591 & val_accuracy = 85.360%\n",
      "epoch = 1 loss = 0.063, accuracy = 97.820%, val_loss = 0.664, val_accuracy = 83.900% & LR: 0.1000\n",
      "epoch = 2 loss = 0.078, accuracy = 97.334%, val_loss = 0.626, val_accuracy = 83.740% & LR: 0.1000\n",
      "epoch = 3 loss = 0.063, accuracy = 97.816%, val_loss = 0.609, val_accuracy = 84.730% & LR: 0.1000\n",
      "epoch = 4 loss = 0.070, accuracy = 97.594%, val_loss = 0.546, val_accuracy = 86.060% & LR: 0.1000\n",
      "epoch = 5 loss = 0.073, accuracy = 97.524%, val_loss = 0.627, val_accuracy = 83.230% & LR: 0.0100\n",
      "Layer: layer1.1.conv2, Sparsity: 50.0%, Accuracy: 0.8323000073432922%\n",
      "Pre fine-tuning: val_loss = 0.627 & val_accuracy = 83.360%\n",
      "epoch = 1 loss = 0.070, accuracy = 97.610%, val_loss = 0.608, val_accuracy = 84.950% & LR: 0.1000\n",
      "epoch = 2 loss = 0.067, accuracy = 97.804%, val_loss = 0.815, val_accuracy = 80.710% & LR: 0.1000\n",
      "epoch = 3 loss = 0.071, accuracy = 97.516%, val_loss = 0.738, val_accuracy = 83.170% & LR: 0.1000\n",
      "epoch = 4 loss = 0.074, accuracy = 97.456%, val_loss = 0.541, val_accuracy = 85.150% & LR: 0.1000\n",
      "epoch = 5 loss = 0.066, accuracy = 97.718%, val_loss = 0.619, val_accuracy = 84.700% & LR: 0.0100\n",
      "Layer: layer1.1.conv2, Sparsity: 90.0%, Accuracy: 0.847000002861023%\n",
      "Pre fine-tuning: val_loss = 0.618 & val_accuracy = 84.690%\n",
      "epoch = 1 loss = 0.062, accuracy = 97.860%, val_loss = 0.644, val_accuracy = 84.090% & LR: 0.1000\n",
      "epoch = 2 loss = 0.074, accuracy = 97.484%, val_loss = 0.676, val_accuracy = 83.270% & LR: 0.1000\n",
      "epoch = 3 loss = 0.072, accuracy = 97.488%, val_loss = 0.663, val_accuracy = 84.020% & LR: 0.1000\n",
      "epoch = 4 loss = 0.068, accuracy = 97.746%, val_loss = 0.608, val_accuracy = 84.180% & LR: 0.1000\n",
      "epoch = 5 loss = 0.065, accuracy = 97.810%, val_loss = 0.595, val_accuracy = 84.700% & LR: 0.0100\n",
      "Layer: layer2.0.conv1, Sparsity: 10.0%, Accuracy: 0.847000002861023%\n",
      "Pre fine-tuning: val_loss = 0.600 & val_accuracy = 84.880%\n",
      "epoch = 1 loss = 0.066, accuracy = 97.686%, val_loss = 0.608, val_accuracy = 84.140% & LR: 0.1000\n",
      "epoch = 2 loss = 0.076, accuracy = 97.424%, val_loss = 0.683, val_accuracy = 83.110% & LR: 0.1000\n",
      "epoch = 3 loss = 0.069, accuracy = 97.596%, val_loss = 0.583, val_accuracy = 84.480% & LR: 0.1000\n",
      "epoch = 4 loss = 0.062, accuracy = 97.904%, val_loss = 0.566, val_accuracy = 86.020% & LR: 0.1000\n",
      "epoch = 5 loss = 0.065, accuracy = 97.862%, val_loss = 0.630, val_accuracy = 83.980% & LR: 0.0100\n",
      "Layer: layer2.0.conv1, Sparsity: 50.0%, Accuracy: 0.8398000001907349%\n",
      "Pre fine-tuning: val_loss = 1.500 & val_accuracy = 65.550%\n",
      "epoch = 1 loss = 0.073, accuracy = 97.498%, val_loss = 0.782, val_accuracy = 82.060% & LR: 0.1000\n",
      "epoch = 2 loss = 0.074, accuracy = 97.510%, val_loss = 0.548, val_accuracy = 85.820% & LR: 0.1000\n",
      "epoch = 3 loss = 0.064, accuracy = 97.860%, val_loss = 0.617, val_accuracy = 84.140% & LR: 0.1000\n",
      "epoch = 4 loss = 0.073, accuracy = 97.412%, val_loss = 0.585, val_accuracy = 84.600% & LR: 0.1000\n",
      "epoch = 5 loss = 0.070, accuracy = 97.558%, val_loss = 0.614, val_accuracy = 83.790% & LR: 0.0100\n",
      "Layer: layer2.0.conv1, Sparsity: 90.0%, Accuracy: 0.8378999829292297%\n",
      "Pre fine-tuning: val_loss = 0.614 & val_accuracy = 83.770%\n",
      "epoch = 1 loss = 0.063, accuracy = 97.844%, val_loss = 0.572, val_accuracy = 85.350% & LR: 0.1000\n",
      "epoch = 2 loss = 0.063, accuracy = 97.804%, val_loss = 0.608, val_accuracy = 84.480% & LR: 0.1000\n",
      "epoch = 3 loss = 0.072, accuracy = 97.520%, val_loss = 0.642, val_accuracy = 83.230% & LR: 0.1000\n",
      "epoch = 4 loss = 0.065, accuracy = 97.744%, val_loss = 0.664, val_accuracy = 83.220% & LR: 0.1000\n",
      "epoch = 5 loss = 0.071, accuracy = 97.532%, val_loss = 0.530, val_accuracy = 86.320% & LR: 0.0100\n",
      "Layer: layer2.0.conv2, Sparsity: 10.0%, Accuracy: 0.8631999492645264%\n",
      "Pre fine-tuning: val_loss = 0.546 & val_accuracy = 86.040%\n",
      "epoch = 1 loss = 0.053, accuracy = 98.180%, val_loss = 0.538, val_accuracy = 85.570% & LR: 0.1000\n",
      "epoch = 2 loss = 0.070, accuracy = 97.648%, val_loss = 0.557, val_accuracy = 84.820% & LR: 0.1000\n",
      "epoch = 3 loss = 0.062, accuracy = 97.916%, val_loss = 0.602, val_accuracy = 85.100% & LR: 0.1000\n",
      "epoch = 4 loss = 0.073, accuracy = 97.542%, val_loss = 0.563, val_accuracy = 85.810% & LR: 0.1000\n",
      "epoch = 5 loss = 0.056, accuracy = 98.118%, val_loss = 0.583, val_accuracy = 85.480% & LR: 0.0100\n",
      "Layer: layer2.0.conv2, Sparsity: 50.0%, Accuracy: 0.8547999858856201%\n",
      "Pre fine-tuning: val_loss = 1.329 & val_accuracy = 69.670%\n",
      "epoch = 1 loss = 0.083, accuracy = 97.144%, val_loss = 0.666, val_accuracy = 83.150% & LR: 0.1000\n",
      "epoch = 2 loss = 0.076, accuracy = 97.410%, val_loss = 0.545, val_accuracy = 85.910% & LR: 0.1000\n",
      "epoch = 3 loss = 0.070, accuracy = 97.570%, val_loss = 0.754, val_accuracy = 81.480% & LR: 0.1000\n",
      "epoch = 4 loss = 0.064, accuracy = 97.862%, val_loss = 0.623, val_accuracy = 83.100% & LR: 0.1000\n",
      "epoch = 5 loss = 0.069, accuracy = 97.670%, val_loss = 0.851, val_accuracy = 79.920% & LR: 0.0100\n",
      "Layer: layer2.0.conv2, Sparsity: 90.0%, Accuracy: 0.7991999983787537%\n",
      "Pre fine-tuning: val_loss = 0.853 & val_accuracy = 79.850%\n",
      "epoch = 1 loss = 0.065, accuracy = 97.696%, val_loss = 0.685, val_accuracy = 83.500% & LR: 0.1000\n",
      "epoch = 2 loss = 0.062, accuracy = 97.868%, val_loss = 0.764, val_accuracy = 82.340% & LR: 0.1000\n",
      "epoch = 3 loss = 0.064, accuracy = 97.852%, val_loss = 0.568, val_accuracy = 84.740% & LR: 0.1000\n",
      "epoch = 4 loss = 0.067, accuracy = 97.710%, val_loss = 0.585, val_accuracy = 85.200% & LR: 0.1000\n",
      "epoch = 5 loss = 0.065, accuracy = 97.794%, val_loss = 0.621, val_accuracy = 84.120% & LR: 0.0100\n",
      "Layer: layer2.0.shortcut.0, Sparsity: 10.0%, Accuracy: 0.8411999940872192%\n",
      "Pre fine-tuning: val_loss = 0.618 & val_accuracy = 84.550%\n",
      "epoch = 1 loss = 0.059, accuracy = 98.044%, val_loss = 0.713, val_accuracy = 82.460% & LR: 0.1000\n",
      "epoch = 2 loss = 0.064, accuracy = 97.836%, val_loss = 0.610, val_accuracy = 85.000% & LR: 0.1000\n",
      "epoch = 3 loss = 0.062, accuracy = 97.868%, val_loss = 0.618, val_accuracy = 84.190% & LR: 0.1000\n",
      "epoch = 4 loss = 0.065, accuracy = 97.758%, val_loss = 0.567, val_accuracy = 84.460% & LR: 0.1000\n",
      "epoch = 5 loss = 0.062, accuracy = 97.964%, val_loss = 0.587, val_accuracy = 85.220% & LR: 0.0100\n",
      "Layer: layer2.0.shortcut.0, Sparsity: 50.0%, Accuracy: 0.8521999716758728%\n",
      "Pre fine-tuning: val_loss = 0.669 & val_accuracy = 83.150%\n",
      "epoch = 1 loss = 0.070, accuracy = 97.660%, val_loss = 0.622, val_accuracy = 83.740% & LR: 0.1000\n",
      "epoch = 2 loss = 0.063, accuracy = 97.870%, val_loss = 0.629, val_accuracy = 84.370% & LR: 0.1000\n",
      "epoch = 3 loss = 0.067, accuracy = 97.718%, val_loss = 0.666, val_accuracy = 83.660% & LR: 0.1000\n",
      "epoch = 4 loss = 0.065, accuracy = 97.778%, val_loss = 0.770, val_accuracy = 81.800% & LR: 0.1000\n",
      "epoch = 5 loss = 0.062, accuracy = 97.882%, val_loss = 0.580, val_accuracy = 85.520% & LR: 0.0100\n",
      "Layer: layer2.0.shortcut.0, Sparsity: 90.0%, Accuracy: 0.8551999926567078%\n",
      "Pre fine-tuning: val_loss = 0.580 & val_accuracy = 85.530%\n",
      "epoch = 1 loss = 0.063, accuracy = 97.866%, val_loss = 0.669, val_accuracy = 83.630% & LR: 0.1000\n",
      "epoch = 2 loss = 0.063, accuracy = 97.834%, val_loss = 0.729, val_accuracy = 82.280% & LR: 0.1000\n",
      "epoch = 3 loss = 0.060, accuracy = 97.998%, val_loss = 0.697, val_accuracy = 83.510% & LR: 0.1000\n",
      "epoch = 4 loss = 0.069, accuracy = 97.594%, val_loss = 0.675, val_accuracy = 84.100% & LR: 0.1000\n",
      "epoch = 5 loss = 0.062, accuracy = 97.896%, val_loss = 0.677, val_accuracy = 83.470% & LR: 0.0100\n",
      "Layer: layer2.1.conv1, Sparsity: 10.0%, Accuracy: 0.8346999883651733%\n",
      "Pre fine-tuning: val_loss = 0.676 & val_accuracy = 83.560%\n",
      "epoch = 1 loss = 0.059, accuracy = 97.982%, val_loss = 0.745, val_accuracy = 82.990% & LR: 0.1000\n",
      "epoch = 2 loss = 0.063, accuracy = 97.864%, val_loss = 0.563, val_accuracy = 85.770% & LR: 0.1000\n",
      "epoch = 3 loss = 0.061, accuracy = 97.898%, val_loss = 0.596, val_accuracy = 85.590% & LR: 0.1000\n",
      "epoch = 4 loss = 0.066, accuracy = 97.774%, val_loss = 0.692, val_accuracy = 83.580% & LR: 0.1000\n",
      "epoch = 5 loss = 0.066, accuracy = 97.776%, val_loss = 0.605, val_accuracy = 84.900% & LR: 0.0100\n",
      "Layer: layer2.1.conv1, Sparsity: 50.0%, Accuracy: 0.8489999771118164%\n",
      "Pre fine-tuning: val_loss = 0.710 & val_accuracy = 83.190%\n",
      "epoch = 1 loss = 0.068, accuracy = 97.654%, val_loss = 0.597, val_accuracy = 85.170% & LR: 0.1000\n",
      "epoch = 2 loss = 0.058, accuracy = 98.086%, val_loss = 0.621, val_accuracy = 84.680% & LR: 0.1000\n",
      "epoch = 3 loss = 0.070, accuracy = 97.622%, val_loss = 0.657, val_accuracy = 83.840% & LR: 0.1000\n",
      "epoch = 4 loss = 0.066, accuracy = 97.736%, val_loss = 0.629, val_accuracy = 83.880% & LR: 0.1000\n",
      "epoch = 5 loss = 0.058, accuracy = 98.034%, val_loss = 0.566, val_accuracy = 85.570% & LR: 0.0100\n",
      "Layer: layer2.1.conv1, Sparsity: 90.0%, Accuracy: 0.8556999564170837%\n",
      "Pre fine-tuning: val_loss = 0.566 & val_accuracy = 85.550%\n",
      "epoch = 1 loss = 0.063, accuracy = 97.884%, val_loss = 0.581, val_accuracy = 85.260% & LR: 0.1000\n",
      "epoch = 2 loss = 0.060, accuracy = 97.992%, val_loss = 0.596, val_accuracy = 84.570% & LR: 0.1000\n",
      "epoch = 3 loss = 0.064, accuracy = 97.798%, val_loss = 0.525, val_accuracy = 86.660% & LR: 0.1000\n",
      "epoch = 4 loss = 0.060, accuracy = 98.008%, val_loss = 0.598, val_accuracy = 84.980% & LR: 0.1000\n",
      "epoch = 5 loss = 0.067, accuracy = 97.684%, val_loss = 0.605, val_accuracy = 83.990% & LR: 0.0100\n",
      "Layer: layer2.1.conv2, Sparsity: 10.0%, Accuracy: 0.8398999571800232%\n",
      "Pre fine-tuning: val_loss = 0.618 & val_accuracy = 84.130%\n",
      "epoch = 1 loss = 0.056, accuracy = 98.096%, val_loss = 0.574, val_accuracy = 85.100% & LR: 0.1000\n",
      "epoch = 2 loss = 0.066, accuracy = 97.754%, val_loss = 0.566, val_accuracy = 85.770% & LR: 0.1000\n",
      "epoch = 3 loss = 0.060, accuracy = 97.950%, val_loss = 0.596, val_accuracy = 84.690% & LR: 0.1000\n",
      "epoch = 4 loss = 0.062, accuracy = 97.896%, val_loss = 0.617, val_accuracy = 84.800% & LR: 0.1000\n",
      "epoch = 5 loss = 0.061, accuracy = 97.896%, val_loss = 0.673, val_accuracy = 84.120% & LR: 0.0100\n",
      "Layer: layer2.1.conv2, Sparsity: 50.0%, Accuracy: 0.8411999940872192%\n",
      "Pre fine-tuning: val_loss = 0.844 & val_accuracy = 82.470%\n",
      "epoch = 1 loss = 0.060, accuracy = 97.942%, val_loss = 0.577, val_accuracy = 85.770% & LR: 0.1000\n",
      "epoch = 2 loss = 0.071, accuracy = 97.568%, val_loss = 0.647, val_accuracy = 84.280% & LR: 0.1000\n",
      "epoch = 3 loss = 0.061, accuracy = 97.886%, val_loss = 0.621, val_accuracy = 85.090% & LR: 0.1000\n",
      "epoch = 4 loss = 0.061, accuracy = 97.896%, val_loss = 0.637, val_accuracy = 84.730% & LR: 0.1000\n",
      "epoch = 5 loss = 0.071, accuracy = 97.616%, val_loss = 0.541, val_accuracy = 85.730% & LR: 0.0100\n",
      "Layer: layer2.1.conv2, Sparsity: 90.0%, Accuracy: 0.8572999835014343%\n",
      "Pre fine-tuning: val_loss = 0.542 & val_accuracy = 85.730%\n",
      "epoch = 1 loss = 0.044, accuracy = 98.548%, val_loss = 0.658, val_accuracy = 83.960% & LR: 0.1000\n",
      "epoch = 2 loss = 0.062, accuracy = 97.862%, val_loss = 0.671, val_accuracy = 83.590% & LR: 0.1000\n",
      "epoch = 3 loss = 0.062, accuracy = 97.956%, val_loss = 0.624, val_accuracy = 85.120% & LR: 0.1000\n",
      "epoch = 4 loss = 0.069, accuracy = 97.700%, val_loss = 0.638, val_accuracy = 84.610% & LR: 0.1000\n",
      "epoch = 5 loss = 0.064, accuracy = 97.778%, val_loss = 0.585, val_accuracy = 85.910% & LR: 0.0100\n",
      "Layer: layer3.0.conv1, Sparsity: 10.0%, Accuracy: 0.8590999841690063%\n",
      "Pre fine-tuning: val_loss = 0.587 & val_accuracy = 85.910%\n",
      "epoch = 1 loss = 0.044, accuracy = 98.526%, val_loss = 0.677, val_accuracy = 82.990% & LR: 0.1000\n",
      "epoch = 2 loss = 0.065, accuracy = 97.832%, val_loss = 0.607, val_accuracy = 85.040% & LR: 0.1000\n",
      "epoch = 3 loss = 0.054, accuracy = 98.108%, val_loss = 0.626, val_accuracy = 83.600% & LR: 0.1000\n",
      "epoch = 4 loss = 0.063, accuracy = 97.964%, val_loss = 0.580, val_accuracy = 85.240% & LR: 0.1000\n",
      "epoch = 5 loss = 0.056, accuracy = 98.030%, val_loss = 0.654, val_accuracy = 84.340% & LR: 0.0100\n",
      "Layer: layer3.0.conv1, Sparsity: 50.0%, Accuracy: 0.8434000015258789%\n",
      "Pre fine-tuning: val_loss = 0.749 & val_accuracy = 80.390%\n",
      "epoch = 1 loss = 0.096, accuracy = 96.726%, val_loss = 0.607, val_accuracy = 84.030% & LR: 0.1000\n",
      "epoch = 2 loss = 0.076, accuracy = 97.406%, val_loss = 0.583, val_accuracy = 84.340% & LR: 0.1000\n",
      "epoch = 3 loss = 0.062, accuracy = 97.900%, val_loss = 0.555, val_accuracy = 85.460% & LR: 0.1000\n",
      "epoch = 4 loss = 0.068, accuracy = 97.652%, val_loss = 0.597, val_accuracy = 84.780% & LR: 0.1000\n",
      "epoch = 5 loss = 0.062, accuracy = 97.942%, val_loss = 0.631, val_accuracy = 84.540% & LR: 0.0100\n",
      "Layer: layer3.0.conv1, Sparsity: 90.0%, Accuracy: 0.8453999757766724%\n",
      "Pre fine-tuning: val_loss = 0.632 & val_accuracy = 84.530%\n",
      "epoch = 1 loss = 0.058, accuracy = 98.056%, val_loss = 0.592, val_accuracy = 85.580% & LR: 0.1000\n",
      "epoch = 2 loss = 0.058, accuracy = 98.084%, val_loss = 0.627, val_accuracy = 84.870% & LR: 0.1000\n",
      "epoch = 3 loss = 0.062, accuracy = 97.894%, val_loss = 0.609, val_accuracy = 85.160% & LR: 0.1000\n",
      "epoch = 4 loss = 0.063, accuracy = 97.802%, val_loss = 0.596, val_accuracy = 84.970% & LR: 0.1000\n",
      "epoch = 5 loss = 0.063, accuracy = 97.846%, val_loss = 0.656, val_accuracy = 84.710% & LR: 0.0100\n",
      "Layer: layer3.0.conv2, Sparsity: 10.0%, Accuracy: 0.8470999598503113%\n",
      "Pre fine-tuning: val_loss = 0.626 & val_accuracy = 84.840%\n",
      "epoch = 1 loss = 0.042, accuracy = 98.588%, val_loss = 0.566, val_accuracy = 86.220% & LR: 0.1000\n",
      "epoch = 2 loss = 0.066, accuracy = 97.734%, val_loss = 0.614, val_accuracy = 85.150% & LR: 0.1000\n",
      "epoch = 3 loss = 0.064, accuracy = 97.826%, val_loss = 0.650, val_accuracy = 84.310% & LR: 0.1000\n",
      "epoch = 4 loss = 0.064, accuracy = 97.824%, val_loss = 0.636, val_accuracy = 83.900% & LR: 0.1000\n",
      "epoch = 5 loss = 0.056, accuracy = 98.094%, val_loss = 0.631, val_accuracy = 85.000% & LR: 0.0100\n",
      "Layer: layer3.0.conv2, Sparsity: 50.0%, Accuracy: 0.8499999642372131%\n",
      "Pre fine-tuning: val_loss = 0.772 & val_accuracy = 77.420%\n",
      "epoch = 1 loss = 0.103, accuracy = 96.416%, val_loss = 0.672, val_accuracy = 82.010% & LR: 0.1000\n",
      "epoch = 2 loss = 0.078, accuracy = 97.322%, val_loss = 0.659, val_accuracy = 82.460% & LR: 0.1000\n",
      "epoch = 3 loss = 0.073, accuracy = 97.496%, val_loss = 0.677, val_accuracy = 82.920% & LR: 0.1000\n",
      "epoch = 4 loss = 0.071, accuracy = 97.586%, val_loss = 0.609, val_accuracy = 84.120% & LR: 0.1000\n",
      "epoch = 5 loss = 0.064, accuracy = 97.802%, val_loss = 0.558, val_accuracy = 85.230% & LR: 0.0100\n",
      "Layer: layer3.0.conv2, Sparsity: 90.0%, Accuracy: 0.8522999882698059%\n",
      "Pre fine-tuning: val_loss = 0.558 & val_accuracy = 85.230%\n",
      "epoch = 1 loss = 0.055, accuracy = 98.130%, val_loss = 0.642, val_accuracy = 83.520% & LR: 0.1000\n",
      "epoch = 2 loss = 0.076, accuracy = 97.336%, val_loss = 0.581, val_accuracy = 85.710% & LR: 0.1000\n",
      "epoch = 3 loss = 0.065, accuracy = 97.808%, val_loss = 0.535, val_accuracy = 86.460% & LR: 0.1000\n",
      "epoch = 4 loss = 0.058, accuracy = 98.142%, val_loss = 0.648, val_accuracy = 83.920% & LR: 0.1000\n",
      "epoch = 5 loss = 0.066, accuracy = 97.674%, val_loss = 0.569, val_accuracy = 85.260% & LR: 0.0100\n",
      "Layer: layer3.0.shortcut.0, Sparsity: 10.0%, Accuracy: 0.8525999784469604%\n",
      "Pre fine-tuning: val_loss = 0.569 & val_accuracy = 85.190%\n",
      "epoch = 1 loss = 0.053, accuracy = 98.256%, val_loss = 0.651, val_accuracy = 84.240% & LR: 0.1000\n",
      "epoch = 2 loss = 0.065, accuracy = 97.812%, val_loss = 0.677, val_accuracy = 83.940% & LR: 0.1000\n",
      "epoch = 3 loss = 0.059, accuracy = 97.924%, val_loss = 0.593, val_accuracy = 85.610% & LR: 0.1000\n",
      "epoch = 4 loss = 0.067, accuracy = 97.762%, val_loss = 0.581, val_accuracy = 85.360% & LR: 0.1000\n",
      "epoch = 5 loss = 0.061, accuracy = 97.952%, val_loss = 0.719, val_accuracy = 82.930% & LR: 0.0100\n",
      "Layer: layer3.0.shortcut.0, Sparsity: 50.0%, Accuracy: 0.8292999863624573%\n",
      "Pre fine-tuning: val_loss = 0.765 & val_accuracy = 82.080%\n",
      "epoch = 1 loss = 0.071, accuracy = 97.628%, val_loss = 0.559, val_accuracy = 85.340% & LR: 0.1000\n",
      "epoch = 2 loss = 0.063, accuracy = 97.942%, val_loss = 0.684, val_accuracy = 83.410% & LR: 0.1000\n",
      "epoch = 3 loss = 0.070, accuracy = 97.650%, val_loss = 0.648, val_accuracy = 84.150% & LR: 0.1000\n",
      "epoch = 4 loss = 0.062, accuracy = 97.894%, val_loss = 0.656, val_accuracy = 84.550% & LR: 0.1000\n",
      "epoch = 5 loss = 0.071, accuracy = 97.592%, val_loss = 0.716, val_accuracy = 83.050% & LR: 0.0100\n",
      "Layer: layer3.0.shortcut.0, Sparsity: 90.0%, Accuracy: 0.8305000066757202%\n",
      "Pre fine-tuning: val_loss = 0.716 & val_accuracy = 83.050%\n",
      "epoch = 1 loss = 0.058, accuracy = 98.078%, val_loss = 0.574, val_accuracy = 85.690% & LR: 0.1000\n",
      "epoch = 2 loss = 0.069, accuracy = 97.616%, val_loss = 0.633, val_accuracy = 84.710% & LR: 0.1000\n",
      "epoch = 3 loss = 0.069, accuracy = 97.638%, val_loss = 0.694, val_accuracy = 83.820% & LR: 0.1000\n",
      "epoch = 4 loss = 0.056, accuracy = 98.020%, val_loss = 0.617, val_accuracy = 84.750% & LR: 0.1000\n",
      "epoch = 5 loss = 0.064, accuracy = 97.716%, val_loss = 0.584, val_accuracy = 85.390% & LR: 0.0100\n",
      "Layer: layer3.1.conv1, Sparsity: 10.0%, Accuracy: 0.8538999557495117%\n",
      "Pre fine-tuning: val_loss = 0.584 & val_accuracy = 85.390%\n",
      "epoch = 1 loss = 0.059, accuracy = 97.970%, val_loss = 0.631, val_accuracy = 84.740% & LR: 0.1000\n",
      "epoch = 2 loss = 0.060, accuracy = 97.890%, val_loss = 0.553, val_accuracy = 86.120% & LR: 0.1000\n",
      "epoch = 3 loss = 0.060, accuracy = 97.964%, val_loss = 0.651, val_accuracy = 83.990% & LR: 0.1000\n",
      "epoch = 4 loss = 0.054, accuracy = 98.234%, val_loss = 0.613, val_accuracy = 84.610% & LR: 0.1000\n",
      "epoch = 5 loss = 0.069, accuracy = 97.626%, val_loss = 0.569, val_accuracy = 85.280% & LR: 0.0100\n",
      "Layer: layer3.1.conv1, Sparsity: 50.0%, Accuracy: 0.8527999520301819%\n",
      "Pre fine-tuning: val_loss = 0.598 & val_accuracy = 83.560%\n",
      "epoch = 1 loss = 0.059, accuracy = 98.000%, val_loss = 0.697, val_accuracy = 82.860% & LR: 0.1000\n",
      "epoch = 2 loss = 0.063, accuracy = 97.814%, val_loss = 0.598, val_accuracy = 85.010% & LR: 0.1000\n",
      "epoch = 3 loss = 0.066, accuracy = 97.788%, val_loss = 0.571, val_accuracy = 85.510% & LR: 0.1000\n",
      "epoch = 4 loss = 0.077, accuracy = 97.392%, val_loss = 0.589, val_accuracy = 84.270% & LR: 0.1000\n",
      "epoch = 5 loss = 0.052, accuracy = 98.204%, val_loss = 0.591, val_accuracy = 85.120% & LR: 0.0100\n",
      "Layer: layer3.1.conv1, Sparsity: 90.0%, Accuracy: 0.8511999845504761%\n",
      "Pre fine-tuning: val_loss = 0.591 & val_accuracy = 85.120%\n",
      "epoch = 1 loss = 0.058, accuracy = 98.066%, val_loss = 0.705, val_accuracy = 82.510% & LR: 0.1000\n",
      "epoch = 2 loss = 0.067, accuracy = 97.706%, val_loss = 0.597, val_accuracy = 84.960% & LR: 0.1000\n",
      "epoch = 3 loss = 0.067, accuracy = 97.680%, val_loss = 0.581, val_accuracy = 85.490% & LR: 0.1000\n",
      "epoch = 4 loss = 0.058, accuracy = 98.022%, val_loss = 0.637, val_accuracy = 84.990% & LR: 0.1000\n",
      "epoch = 5 loss = 0.068, accuracy = 97.678%, val_loss = 0.643, val_accuracy = 83.630% & LR: 0.0100\n",
      "Layer: layer3.1.conv2, Sparsity: 10.0%, Accuracy: 0.8362999558448792%\n",
      "Pre fine-tuning: val_loss = 0.643 & val_accuracy = 83.630%\n",
      "epoch = 1 loss = 0.057, accuracy = 98.092%, val_loss = 0.612, val_accuracy = 85.120% & LR: 0.1000\n",
      "epoch = 2 loss = 0.058, accuracy = 98.040%, val_loss = 0.569, val_accuracy = 85.610% & LR: 0.1000\n",
      "epoch = 3 loss = 0.066, accuracy = 97.756%, val_loss = 0.596, val_accuracy = 85.410% & LR: 0.1000\n",
      "epoch = 4 loss = 0.061, accuracy = 97.934%, val_loss = 0.605, val_accuracy = 85.500% & LR: 0.1000\n",
      "epoch = 5 loss = 0.065, accuracy = 97.738%, val_loss = 0.545, val_accuracy = 85.590% & LR: 0.0100\n",
      "Layer: layer3.1.conv2, Sparsity: 50.0%, Accuracy: 0.85589998960495%\n",
      "Pre fine-tuning: val_loss = 0.686 & val_accuracy = 84.200%\n",
      "epoch = 1 loss = 0.058, accuracy = 98.094%, val_loss = 0.585, val_accuracy = 84.990% & LR: 0.1000\n",
      "epoch = 2 loss = 0.066, accuracy = 97.740%, val_loss = 0.576, val_accuracy = 85.680% & LR: 0.1000\n",
      "epoch = 3 loss = 0.063, accuracy = 97.808%, val_loss = 0.588, val_accuracy = 84.820% & LR: 0.1000\n",
      "epoch = 4 loss = 0.061, accuracy = 97.922%, val_loss = 0.605, val_accuracy = 84.980% & LR: 0.1000\n",
      "epoch = 5 loss = 0.067, accuracy = 97.710%, val_loss = 0.651, val_accuracy = 84.690% & LR: 0.0100\n",
      "Layer: layer3.1.conv2, Sparsity: 90.0%, Accuracy: 0.8468999862670898%\n",
      "Pre fine-tuning: val_loss = 0.651 & val_accuracy = 84.690%\n",
      "epoch = 1 loss = 0.056, accuracy = 98.096%, val_loss = 0.624, val_accuracy = 85.120% & LR: 0.1000\n",
      "epoch = 2 loss = 0.062, accuracy = 97.848%, val_loss = 0.647, val_accuracy = 83.710% & LR: 0.1000\n",
      "epoch = 3 loss = 0.058, accuracy = 98.060%, val_loss = 0.573, val_accuracy = 85.710% & LR: 0.1000\n",
      "epoch = 4 loss = 0.062, accuracy = 97.830%, val_loss = 0.586, val_accuracy = 85.250% & LR: 0.1000\n",
      "epoch = 5 loss = 0.064, accuracy = 97.816%, val_loss = 0.597, val_accuracy = 85.340% & LR: 0.0100\n",
      "Layer: layer4.0.conv1, Sparsity: 10.0%, Accuracy: 0.8533999919891357%\n",
      "Pre fine-tuning: val_loss = 0.597 & val_accuracy = 85.340%\n",
      "epoch = 1 loss = 0.061, accuracy = 97.912%, val_loss = 0.617, val_accuracy = 84.700% & LR: 0.1000\n",
      "epoch = 2 loss = 0.068, accuracy = 97.748%, val_loss = 0.629, val_accuracy = 84.490% & LR: 0.1000\n",
      "epoch = 3 loss = 0.065, accuracy = 97.774%, val_loss = 0.615, val_accuracy = 84.800% & LR: 0.1000\n",
      "epoch = 4 loss = 0.057, accuracy = 98.024%, val_loss = 0.732, val_accuracy = 83.400% & LR: 0.1000\n",
      "epoch = 5 loss = 0.064, accuracy = 97.824%, val_loss = 0.622, val_accuracy = 84.570% & LR: 0.0100\n",
      "Layer: layer4.0.conv1, Sparsity: 50.0%, Accuracy: 0.8456999659538269%\n",
      "Pre fine-tuning: val_loss = 0.680 & val_accuracy = 82.550%\n",
      "epoch = 1 loss = 0.060, accuracy = 97.916%, val_loss = 0.687, val_accuracy = 83.840% & LR: 0.1000\n",
      "epoch = 2 loss = 0.067, accuracy = 97.694%, val_loss = 0.561, val_accuracy = 85.610% & LR: 0.1000\n",
      "epoch = 3 loss = 0.068, accuracy = 97.644%, val_loss = 0.769, val_accuracy = 82.260% & LR: 0.1000\n",
      "epoch = 4 loss = 0.064, accuracy = 97.834%, val_loss = 0.541, val_accuracy = 86.440% & LR: 0.1000\n",
      "epoch = 5 loss = 0.060, accuracy = 97.834%, val_loss = 0.540, val_accuracy = 86.480% & LR: 0.0100\n",
      "Layer: layer4.0.conv1, Sparsity: 90.0%, Accuracy: 0.864799976348877%\n",
      "Pre fine-tuning: val_loss = 0.540 & val_accuracy = 86.480%\n",
      "epoch = 1 loss = 0.049, accuracy = 98.354%, val_loss = 0.594, val_accuracy = 85.690% & LR: 0.1000\n",
      "epoch = 2 loss = 0.067, accuracy = 97.696%, val_loss = 0.627, val_accuracy = 84.530% & LR: 0.1000\n",
      "epoch = 3 loss = 0.061, accuracy = 97.942%, val_loss = 0.660, val_accuracy = 83.980% & LR: 0.1000\n",
      "epoch = 4 loss = 0.060, accuracy = 97.984%, val_loss = 0.563, val_accuracy = 86.130% & LR: 0.1000\n",
      "epoch = 5 loss = 0.061, accuracy = 97.974%, val_loss = 0.630, val_accuracy = 84.780% & LR: 0.0100\n",
      "Layer: layer4.0.conv2, Sparsity: 10.0%, Accuracy: 0.8477999567985535%\n",
      "Pre fine-tuning: val_loss = 0.630 & val_accuracy = 84.780%\n",
      "epoch = 1 loss = 0.062, accuracy = 97.916%, val_loss = 0.632, val_accuracy = 83.940% & LR: 0.1000\n",
      "epoch = 2 loss = 0.065, accuracy = 97.836%, val_loss = 0.549, val_accuracy = 85.870% & LR: 0.1000\n",
      "epoch = 3 loss = 0.057, accuracy = 97.992%, val_loss = 0.668, val_accuracy = 84.270% & LR: 0.1000\n",
      "epoch = 4 loss = 0.064, accuracy = 97.850%, val_loss = 0.607, val_accuracy = 85.290% & LR: 0.1000\n",
      "epoch = 5 loss = 0.057, accuracy = 98.030%, val_loss = 0.662, val_accuracy = 84.850% & LR: 0.0100\n",
      "Layer: layer4.0.conv2, Sparsity: 50.0%, Accuracy: 0.8484999537467957%\n",
      "Pre fine-tuning: val_loss = 0.608 & val_accuracy = 84.540%\n",
      "epoch = 1 loss = 0.045, accuracy = 98.538%, val_loss = 0.784, val_accuracy = 82.810% & LR: 0.1000\n",
      "epoch = 2 loss = 0.070, accuracy = 97.682%, val_loss = 0.621, val_accuracy = 84.800% & LR: 0.1000\n",
      "epoch = 3 loss = 0.066, accuracy = 97.726%, val_loss = 0.627, val_accuracy = 85.050% & LR: 0.1000\n",
      "epoch = 4 loss = 0.054, accuracy = 98.208%, val_loss = 0.592, val_accuracy = 85.050% & LR: 0.1000\n",
      "epoch = 5 loss = 0.064, accuracy = 97.796%, val_loss = 0.547, val_accuracy = 86.020% & LR: 0.0100\n",
      "Layer: layer4.0.conv2, Sparsity: 90.0%, Accuracy: 0.8601999878883362%\n",
      "Pre fine-tuning: val_loss = 0.547 & val_accuracy = 86.030%\n",
      "epoch = 1 loss = 0.052, accuracy = 98.160%, val_loss = 0.687, val_accuracy = 84.270% & LR: 0.1000\n",
      "epoch = 2 loss = 0.072, accuracy = 97.584%, val_loss = 0.675, val_accuracy = 83.390% & LR: 0.1000\n",
      "epoch = 3 loss = 0.054, accuracy = 98.084%, val_loss = 0.587, val_accuracy = 85.940% & LR: 0.1000\n",
      "epoch = 4 loss = 0.054, accuracy = 98.228%, val_loss = 0.589, val_accuracy = 85.370% & LR: 0.1000\n",
      "epoch = 5 loss = 0.066, accuracy = 97.700%, val_loss = 0.614, val_accuracy = 83.620% & LR: 0.0100\n",
      "Layer: layer4.0.shortcut.0, Sparsity: 10.0%, Accuracy: 0.8361999988555908%\n",
      "Pre fine-tuning: val_loss = 0.617 & val_accuracy = 83.530%\n",
      "epoch = 1 loss = 0.055, accuracy = 98.142%, val_loss = 0.631, val_accuracy = 84.980% & LR: 0.1000\n",
      "epoch = 2 loss = 0.066, accuracy = 97.810%, val_loss = 0.620, val_accuracy = 84.760% & LR: 0.1000\n",
      "epoch = 3 loss = 0.054, accuracy = 98.210%, val_loss = 0.597, val_accuracy = 85.490% & LR: 0.1000\n",
      "epoch = 4 loss = 0.058, accuracy = 98.016%, val_loss = 0.631, val_accuracy = 84.190% & LR: 0.1000\n",
      "epoch = 5 loss = 0.061, accuracy = 97.884%, val_loss = 0.537, val_accuracy = 85.890% & LR: 0.0100\n",
      "Layer: layer4.0.shortcut.0, Sparsity: 50.0%, Accuracy: 0.8588999509811401%\n",
      "Pre fine-tuning: val_loss = 0.533 & val_accuracy = 85.780%\n",
      "epoch = 1 loss = 0.060, accuracy = 97.976%, val_loss = 0.630, val_accuracy = 85.040% & LR: 0.1000\n",
      "epoch = 2 loss = 0.060, accuracy = 97.914%, val_loss = 0.618, val_accuracy = 85.120% & LR: 0.1000\n",
      "epoch = 3 loss = 0.062, accuracy = 97.920%, val_loss = 0.691, val_accuracy = 83.040% & LR: 0.1000\n",
      "epoch = 4 loss = 0.061, accuracy = 97.970%, val_loss = 0.583, val_accuracy = 85.090% & LR: 0.1000\n",
      "epoch = 5 loss = 0.060, accuracy = 97.924%, val_loss = 0.570, val_accuracy = 85.920% & LR: 0.0100\n",
      "Layer: layer4.0.shortcut.0, Sparsity: 90.0%, Accuracy: 0.8592000007629395%\n",
      "Pre fine-tuning: val_loss = 0.570 & val_accuracy = 85.920%\n",
      "epoch = 1 loss = 0.053, accuracy = 98.242%, val_loss = 0.554, val_accuracy = 85.680% & LR: 0.1000\n",
      "epoch = 2 loss = 0.062, accuracy = 97.884%, val_loss = 0.546, val_accuracy = 86.090% & LR: 0.1000\n",
      "epoch = 3 loss = 0.063, accuracy = 97.810%, val_loss = 0.618, val_accuracy = 85.120% & LR: 0.1000\n",
      "epoch = 4 loss = 0.062, accuracy = 97.908%, val_loss = 0.532, val_accuracy = 86.280% & LR: 0.1000\n",
      "epoch = 5 loss = 0.056, accuracy = 98.024%, val_loss = 0.549, val_accuracy = 86.470% & LR: 0.0100\n",
      "Layer: layer4.1.conv1, Sparsity: 10.0%, Accuracy: 0.8646999597549438%\n",
      "Pre fine-tuning: val_loss = 0.549 & val_accuracy = 86.470%\n",
      "epoch = 1 loss = 0.053, accuracy = 98.196%, val_loss = 0.596, val_accuracy = 85.320% & LR: 0.1000\n",
      "epoch = 2 loss = 0.060, accuracy = 97.980%, val_loss = 0.613, val_accuracy = 85.230% & LR: 0.1000\n",
      "epoch = 3 loss = 0.066, accuracy = 97.652%, val_loss = 0.611, val_accuracy = 84.450% & LR: 0.1000\n",
      "epoch = 4 loss = 0.058, accuracy = 97.968%, val_loss = 0.557, val_accuracy = 85.980% & LR: 0.1000\n",
      "epoch = 5 loss = 0.060, accuracy = 97.994%, val_loss = 0.617, val_accuracy = 85.620% & LR: 0.0100\n",
      "Layer: layer4.1.conv1, Sparsity: 50.0%, Accuracy: 0.8561999797821045%\n",
      "Pre fine-tuning: val_loss = 0.617 & val_accuracy = 85.620%\n",
      "epoch = 1 loss = 0.064, accuracy = 97.816%, val_loss = 0.773, val_accuracy = 81.880% & LR: 0.1000\n",
      "epoch = 2 loss = 0.059, accuracy = 97.922%, val_loss = 0.623, val_accuracy = 84.150% & LR: 0.1000\n",
      "epoch = 3 loss = 0.061, accuracy = 97.942%, val_loss = 0.545, val_accuracy = 86.300% & LR: 0.1000\n",
      "epoch = 4 loss = 0.058, accuracy = 97.958%, val_loss = 0.685, val_accuracy = 84.730% & LR: 0.1000\n",
      "epoch = 5 loss = 0.061, accuracy = 97.896%, val_loss = 0.591, val_accuracy = 86.140% & LR: 0.0100\n",
      "Layer: layer4.1.conv1, Sparsity: 90.0%, Accuracy: 0.8613999485969543%\n",
      "Pre fine-tuning: val_loss = 0.591 & val_accuracy = 86.140%\n",
      "epoch = 1 loss = 0.049, accuracy = 98.402%, val_loss = 0.662, val_accuracy = 84.560% & LR: 0.1000\n",
      "epoch = 2 loss = 0.058, accuracy = 97.982%, val_loss = 0.617, val_accuracy = 85.370% & LR: 0.1000\n",
      "epoch = 3 loss = 0.065, accuracy = 97.806%, val_loss = 0.613, val_accuracy = 85.020% & LR: 0.1000\n",
      "epoch = 4 loss = 0.056, accuracy = 98.114%, val_loss = 0.601, val_accuracy = 85.790% & LR: 0.1000\n",
      "epoch = 5 loss = 0.061, accuracy = 97.922%, val_loss = 0.586, val_accuracy = 85.070% & LR: 0.0100\n",
      "Layer: layer4.1.conv2, Sparsity: 10.0%, Accuracy: 0.8506999611854553%\n",
      "Pre fine-tuning: val_loss = 0.586 & val_accuracy = 85.070%\n",
      "epoch = 1 loss = 0.056, accuracy = 98.140%, val_loss = 0.625, val_accuracy = 84.970% & LR: 0.1000\n",
      "epoch = 2 loss = 0.060, accuracy = 98.010%, val_loss = 0.582, val_accuracy = 85.100% & LR: 0.1000\n",
      "epoch = 3 loss = 0.058, accuracy = 98.016%, val_loss = 0.560, val_accuracy = 85.750% & LR: 0.1000\n",
      "epoch = 4 loss = 0.055, accuracy = 98.148%, val_loss = 0.551, val_accuracy = 86.260% & LR: 0.1000\n",
      "epoch = 5 loss = 0.065, accuracy = 97.792%, val_loss = 0.570, val_accuracy = 85.490% & LR: 0.0100\n",
      "Layer: layer4.1.conv2, Sparsity: 50.0%, Accuracy: 0.8549000024795532%\n",
      "Pre fine-tuning: val_loss = 0.570 & val_accuracy = 85.490%\n",
      "epoch = 1 loss = 0.060, accuracy = 97.926%, val_loss = 0.555, val_accuracy = 86.050% & LR: 0.1000\n",
      "epoch = 2 loss = 0.058, accuracy = 98.022%, val_loss = 0.635, val_accuracy = 84.630% & LR: 0.1000\n",
      "epoch = 3 loss = 0.062, accuracy = 97.924%, val_loss = 0.737, val_accuracy = 83.310% & LR: 0.1000\n",
      "epoch = 4 loss = 0.055, accuracy = 98.228%, val_loss = 0.664, val_accuracy = 84.350% & LR: 0.1000\n",
      "epoch = 5 loss = 0.062, accuracy = 97.940%, val_loss = 0.543, val_accuracy = 86.010% & LR: 0.0100\n",
      "Layer: layer4.1.conv2, Sparsity: 90.0%, Accuracy: 0.8600999712944031%\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Error(s) in loading state_dict for ResNet:\n\tMissing key(s) in state_dict: \"layer1.0.conv1.weight_orig\", \"layer1.0.conv1.weight_mask\", \"layer1.0.conv2.weight_orig\", \"layer1.0.conv2.weight_mask\", \"layer1.1.conv1.weight_orig\", \"layer1.1.conv1.weight_mask\", \"layer1.1.conv2.weight_orig\", \"layer1.1.conv2.weight_mask\", \"layer2.0.conv1.weight_orig\", \"layer2.0.conv1.weight_mask\", \"layer2.0.conv2.weight_orig\", \"layer2.0.conv2.weight_mask\", \"layer2.0.shortcut.0.weight_orig\", \"layer2.0.shortcut.0.weight_mask\", \"layer2.1.conv1.weight_orig\", \"layer2.1.conv1.weight_mask\", \"layer2.1.conv2.weight_orig\", \"layer2.1.conv2.weight_mask\", \"layer3.0.conv1.weight_orig\", \"layer3.0.conv1.weight_mask\", \"layer3.0.conv2.weight_orig\", \"layer3.0.conv2.weight_mask\", \"layer3.0.shortcut.0.weight_orig\", \"layer3.0.shortcut.0.weight_mask\", \"layer3.1.conv1.weight_orig\", \"layer3.1.conv1.weight_mask\", \"layer3.1.conv2.weight_orig\", \"layer3.1.conv2.weight_mask\", \"layer4.0.conv1.weight_orig\", \"layer4.0.conv1.weight_mask\", \"layer4.0.conv2.weight_orig\", \"layer4.0.conv2.weight_mask\", \"layer4.0.shortcut.0.weight_orig\", \"layer4.0.shortcut.0.weight_mask\", \"layer4.1.conv1.weight_orig\", \"layer4.1.conv1.weight_mask\", \"layer4.1.conv2.weight_orig\", \"layer4.1.conv2.weight_mask\". \n\tUnexpected key(s) in state_dict: \"layer1.0.conv1.weight\", \"layer1.0.conv2.weight\", \"layer1.1.conv1.weight\", \"layer1.1.conv2.weight\", \"layer2.0.conv1.weight\", \"layer2.0.conv2.weight\", \"layer2.0.shortcut.0.weight\", \"layer2.1.conv1.weight\", \"layer2.1.conv2.weight\", \"layer3.0.conv1.weight\", \"layer3.0.conv2.weight\", \"layer3.0.shortcut.0.weight\", \"layer3.1.conv1.weight\", \"layer3.1.conv2.weight\", \"layer4.0.conv1.weight\", \"layer4.0.conv2.weight\", \"layer4.0.shortcut.0.weight\", \"layer4.1.conv1.weight\", \"layer4.1.conv2.weight\". ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m/home/akshat_gosain/SAiDL/Pruning2resnet18.ipynb Cell 22\u001b[0m line \u001b[0;36m1\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu/home/akshat_gosain/SAiDL/Pruning2resnet18.ipynb#X26sdnNjb2RlLXJlbW90ZQ%3D%3D?line=7'>8</a>\u001b[0m device \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mdevice(\u001b[39m\"\u001b[39m\u001b[39mcuda\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m torch\u001b[39m.\u001b[39mcuda\u001b[39m.\u001b[39mis_available() \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mcpu\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/home/akshat_gosain/SAiDL/Pruning2resnet18.ipynb#X26sdnNjb2RlLXJlbW90ZQ%3D%3D?line=9'>10</a>\u001b[0m \u001b[39m# Run the sensitivity analysis with 5 epochs for fine-tuning\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell://wsl%2Bubuntu/home/akshat_gosain/SAiDL/Pruning2resnet18.ipynb#X26sdnNjb2RlLXJlbW90ZQ%3D%3D?line=10'>11</a>\u001b[0m sensitivity_analysis(model, train_loader, test_loader, device, num_epochs\u001b[39m=\u001b[39;49m\u001b[39m5\u001b[39;49m)\n",
      "\u001b[1;32m/home/akshat_gosain/SAiDL/Pruning2resnet18.ipynb Cell 22\u001b[0m line \u001b[0;36m3\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/home/akshat_gosain/SAiDL/Pruning2resnet18.ipynb#X26sdnNjb2RlLXJlbW90ZQ%3D%3D?line=29'>30</a>\u001b[0m             module\u001b[39m.\u001b[39mweight\u001b[39m.\u001b[39mdata \u001b[39m=\u001b[39m original_weights\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/home/akshat_gosain/SAiDL/Pruning2resnet18.ipynb#X26sdnNjb2RlLXJlbW90ZQ%3D%3D?line=31'>32</a>\u001b[0m \u001b[39m# Reset the weights of the model to their original state\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell://wsl%2Bubuntu/home/akshat_gosain/SAiDL/Pruning2resnet18.ipynb#X26sdnNjb2RlLXJlbW90ZQ%3D%3D?line=32'>33</a>\u001b[0m model\u001b[39m.\u001b[39;49mload_state_dict(original_state_dict)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:2153\u001b[0m, in \u001b[0;36mModule.load_state_dict\u001b[0;34m(self, state_dict, strict, assign)\u001b[0m\n\u001b[1;32m   2148\u001b[0m         error_msgs\u001b[39m.\u001b[39minsert(\n\u001b[1;32m   2149\u001b[0m             \u001b[39m0\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mMissing key(s) in state_dict: \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m. \u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[1;32m   2150\u001b[0m                 \u001b[39m'\u001b[39m\u001b[39m, \u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mjoin(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mk\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m'\u001b[39m \u001b[39mfor\u001b[39;00m k \u001b[39min\u001b[39;00m missing_keys)))\n\u001b[1;32m   2152\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(error_msgs) \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m-> 2153\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\u001b[39m'\u001b[39m\u001b[39mError(s) in loading state_dict for \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m:\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\\t\u001b[39;00m\u001b[39m{}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[1;32m   2154\u001b[0m                        \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\\t\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mjoin(error_msgs)))\n\u001b[1;32m   2155\u001b[0m \u001b[39mreturn\u001b[39;00m _IncompatibleKeys(missing_keys, unexpected_keys)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Error(s) in loading state_dict for ResNet:\n\tMissing key(s) in state_dict: \"layer1.0.conv1.weight_orig\", \"layer1.0.conv1.weight_mask\", \"layer1.0.conv2.weight_orig\", \"layer1.0.conv2.weight_mask\", \"layer1.1.conv1.weight_orig\", \"layer1.1.conv1.weight_mask\", \"layer1.1.conv2.weight_orig\", \"layer1.1.conv2.weight_mask\", \"layer2.0.conv1.weight_orig\", \"layer2.0.conv1.weight_mask\", \"layer2.0.conv2.weight_orig\", \"layer2.0.conv2.weight_mask\", \"layer2.0.shortcut.0.weight_orig\", \"layer2.0.shortcut.0.weight_mask\", \"layer2.1.conv1.weight_orig\", \"layer2.1.conv1.weight_mask\", \"layer2.1.conv2.weight_orig\", \"layer2.1.conv2.weight_mask\", \"layer3.0.conv1.weight_orig\", \"layer3.0.conv1.weight_mask\", \"layer3.0.conv2.weight_orig\", \"layer3.0.conv2.weight_mask\", \"layer3.0.shortcut.0.weight_orig\", \"layer3.0.shortcut.0.weight_mask\", \"layer3.1.conv1.weight_orig\", \"layer3.1.conv1.weight_mask\", \"layer3.1.conv2.weight_orig\", \"layer3.1.conv2.weight_mask\", \"layer4.0.conv1.weight_orig\", \"layer4.0.conv1.weight_mask\", \"layer4.0.conv2.weight_orig\", \"layer4.0.conv2.weight_mask\", \"layer4.0.shortcut.0.weight_orig\", \"layer4.0.shortcut.0.weight_mask\", \"layer4.1.conv1.weight_orig\", \"layer4.1.conv1.weight_mask\", \"layer4.1.conv2.weight_orig\", \"layer4.1.conv2.weight_mask\". \n\tUnexpected key(s) in state_dict: \"layer1.0.conv1.weight\", \"layer1.0.conv2.weight\", \"layer1.1.conv1.weight\", \"layer1.1.conv2.weight\", \"layer2.0.conv1.weight\", \"layer2.0.conv2.weight\", \"layer2.0.shortcut.0.weight\", \"layer2.1.conv1.weight\", \"layer2.1.conv2.weight\", \"layer3.0.conv1.weight\", \"layer3.0.conv2.weight\", \"layer3.0.shortcut.0.weight\", \"layer3.1.conv1.weight\", \"layer3.1.conv2.weight\", \"layer4.0.conv1.weight\", \"layer4.0.conv2.weight\", \"layer4.0.shortcut.0.weight\", \"layer4.1.conv1.weight\", \"layer4.1.conv2.weight\". "
     ]
    }
   ],
   "source": [
    "# Load the model\n",
    "model = new_to_be_pruned_model\n",
    "\n",
    "# Prepare your data loaders\n",
    "train_loader, test_loader = prepare_data_loaders()\n",
    "\n",
    "# Specify the device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Run the sensitivity analysis with 5 epochs for fine-tuning\n",
    "sensitivity_analysis(model, train_loader, test_loader, device, num_epochs=5)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ignore the error, very minor mistake in the end, didn't realise before running ;(\n",
    "    \n",
    "The sensitivity analysis is done, it took approx 6hours+ for this to run even on dedicated rtx gpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the model\n",
    "model = new_to_be_pruned_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute final pruning rate using 20% global unstructured pruning with 21 such pruning rounds\n",
    "pruning_rates = []\n",
    "for i in range(1, 22):\n",
    "    final_pruning_rate = compute_final_pruning_rate(pruning_rate = 0.2, num_iterations = i)\n",
    "    pruning_rates.append(final_pruning_rate * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set regularization strengths and learning rate\n",
    "l1_regularization_strength = 0\n",
    "l2_regularization_strength = 1e-4\n",
    "learning_rate = 1e-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the pre-trained model\n",
    "_, eval_accuracy = evaluate_model(\n",
    "    model = model, test_loader=test_loader,\n",
    "    device = device, criterion = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global sparsity = 0.000% & val_accuracy = 90.030%\n"
     ]
    }
   ],
   "source": [
    "# Measure the sparsity of the pre-trained model\n",
    "num_zeros, num_elements, sparsity = measure_global_sparsity(model)\n",
    "print(f\"Global sparsity = {sparsity:.3f}% & val_accuracy = {eval_accuracy * 100:.3f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a deep copy of the pre-trained model\n",
    "pruned_model = copy.deepcopy(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate_decay = 0.1\n",
    "model_filename_prefix = \"pruned_model\"\n",
    "model_dir = \"/home/akshat_gosain/SAiDL/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Pruning and Finetuning 1/21\n",
      "Pruning...\n",
      "Global sparsity = 20.017% & val_accuracy = 90.030%\n",
      "\n",
      "Fine-tuning...\n",
      "Pre fine-tuning: val_loss = 0.311 & val_accuracy = 90.030%\n",
      "epoch = 1 loss = 0.780, accuracy = 73.136%, val_loss = 0.711, val_accuracy = 75.750% & LR: 0.1000\n",
      "epoch = 2 loss = 0.490, accuracy = 83.272%, val_loss = 0.556, val_accuracy = 81.100% & LR: 0.1000\n",
      "epoch = 3 loss = 0.390, accuracy = 86.496%, val_loss = 0.569, val_accuracy = 81.250% & LR: 0.1000\n",
      "epoch = 4 loss = 0.319, accuracy = 88.874%, val_loss = 0.506, val_accuracy = 83.180% & LR: 0.1000\n",
      "epoch = 5 loss = 0.271, accuracy = 90.596%, val_loss = 0.521, val_accuracy = 83.170% & LR: 0.0100\n",
      "epoch = 6 loss = 0.104, accuracy = 96.582%, val_loss = 0.330, val_accuracy = 89.430% & LR: 0.0100\n",
      "epoch = 7 loss = 0.053, accuracy = 98.438%, val_loss = 0.351, val_accuracy = 89.390% & LR: 0.0100\n",
      "epoch = 8 loss = 0.034, accuracy = 99.044%, val_loss = 0.375, val_accuracy = 89.220% & LR: 0.0100\n",
      "epoch = 9 loss = 0.021, accuracy = 99.530%, val_loss = 0.396, val_accuracy = 89.310% & LR: 0.0100\n",
      "epoch = 10 loss = 0.013, accuracy = 99.770%, val_loss = 0.418, val_accuracy = 89.230% & LR: 0.0010\n",
      "epoch = 11 loss = 0.009, accuracy = 99.866%, val_loss = 0.418, val_accuracy = 89.410% & LR: 0.0010\n",
      "epoch = 12 loss = 0.008, accuracy = 99.930%, val_loss = 0.416, val_accuracy = 89.440% & LR: 0.0010\n",
      "Post fine-tuning: Global sparsity = 20.017% & val_accuracy = 89.440%\n",
      "\n",
      "Pruning and Finetuning 2/21\n",
      "Pruning...\n",
      "Global sparsity = 36.031% & val_accuracy = 89.440%\n",
      "\n",
      "Fine-tuning...\n",
      "Pre fine-tuning: val_loss = 0.416 & val_accuracy = 89.440%\n",
      "epoch = 1 loss = 0.244, accuracy = 91.466%, val_loss = 0.575, val_accuracy = 82.430% & LR: 0.1000\n",
      "epoch = 2 loss = 0.211, accuracy = 92.566%, val_loss = 0.664, val_accuracy = 80.490% & LR: 0.1000\n",
      "epoch = 3 loss = 0.180, accuracy = 93.718%, val_loss = 0.531, val_accuracy = 84.640% & LR: 0.1000\n",
      "epoch = 4 loss = 0.163, accuracy = 94.306%, val_loss = 0.545, val_accuracy = 82.890% & LR: 0.1000\n",
      "epoch = 5 loss = 0.144, accuracy = 95.002%, val_loss = 0.520, val_accuracy = 85.280% & LR: 0.0100\n",
      "epoch = 6 loss = 0.040, accuracy = 98.808%, val_loss = 0.391, val_accuracy = 88.760% & LR: 0.0100\n",
      "epoch = 7 loss = 0.014, accuracy = 99.790%, val_loss = 0.399, val_accuracy = 88.990% & LR: 0.0100\n",
      "epoch = 8 loss = 0.009, accuracy = 99.900%, val_loss = 0.411, val_accuracy = 89.000% & LR: 0.0100\n",
      "epoch = 9 loss = 0.006, accuracy = 99.938%, val_loss = 0.421, val_accuracy = 89.020% & LR: 0.0100\n",
      "epoch = 10 loss = 0.005, accuracy = 99.968%, val_loss = 0.429, val_accuracy = 89.120% & LR: 0.0010\n",
      "epoch = 11 loss = 0.004, accuracy = 99.980%, val_loss = 0.433, val_accuracy = 88.920% & LR: 0.0010\n",
      "epoch = 12 loss = 0.004, accuracy = 99.988%, val_loss = 0.432, val_accuracy = 89.110% & LR: 0.0010\n",
      "Post fine-tuning: Global sparsity = 36.031% & val_accuracy = 89.110%\n",
      "\n",
      "Pruning and Finetuning 3/21\n",
      "Pruning...\n",
      "Global sparsity = 48.842% & val_accuracy = 89.110%\n",
      "\n",
      "Fine-tuning...\n",
      "Pre fine-tuning: val_loss = 0.432 & val_accuracy = 89.110%\n",
      "epoch = 1 loss = 0.121, accuracy = 95.618%, val_loss = 0.800, val_accuracy = 79.780% & LR: 0.1000\n",
      "epoch = 2 loss = 0.143, accuracy = 95.058%, val_loss = 0.538, val_accuracy = 84.380% & LR: 0.1000\n",
      "epoch = 3 loss = 0.120, accuracy = 95.866%, val_loss = 0.533, val_accuracy = 85.850% & LR: 0.1000\n",
      "epoch = 4 loss = 0.121, accuracy = 95.846%, val_loss = 0.625, val_accuracy = 83.530% & LR: 0.1000\n",
      "epoch = 5 loss = 0.107, accuracy = 96.298%, val_loss = 0.604, val_accuracy = 84.310% & LR: 0.0100\n",
      "epoch = 6 loss = 0.031, accuracy = 99.068%, val_loss = 0.404, val_accuracy = 89.100% & LR: 0.0100\n",
      "epoch = 7 loss = 0.009, accuracy = 99.860%, val_loss = 0.419, val_accuracy = 89.070% & LR: 0.0100\n",
      "epoch = 8 loss = 0.006, accuracy = 99.960%, val_loss = 0.422, val_accuracy = 89.080% & LR: 0.0100\n",
      "epoch = 9 loss = 0.004, accuracy = 99.972%, val_loss = 0.428, val_accuracy = 89.220% & LR: 0.0100\n",
      "epoch = 10 loss = 0.003, accuracy = 99.988%, val_loss = 0.430, val_accuracy = 89.250% & LR: 0.0010\n",
      "epoch = 11 loss = 0.003, accuracy = 99.998%, val_loss = 0.432, val_accuracy = 89.130% & LR: 0.0010\n",
      "epoch = 12 loss = 0.003, accuracy = 99.992%, val_loss = 0.432, val_accuracy = 89.180% & LR: 0.0010\n",
      "Post fine-tuning: Global sparsity = 48.842% & val_accuracy = 89.180%\n",
      "\n",
      "Pruning and Finetuning 4/21\n",
      "Pruning...\n",
      "Global sparsity = 59.090% & val_accuracy = 89.180%\n",
      "\n",
      "Fine-tuning...\n",
      "Pre fine-tuning: val_loss = 0.432 & val_accuracy = 89.180%\n",
      "epoch = 1 loss = 0.083, accuracy = 97.094%, val_loss = 0.728, val_accuracy = 81.290% & LR: 0.1000\n",
      "epoch = 2 loss = 0.131, accuracy = 95.466%, val_loss = 0.676, val_accuracy = 82.200% & LR: 0.1000\n",
      "epoch = 3 loss = 0.106, accuracy = 96.354%, val_loss = 0.764, val_accuracy = 80.950% & LR: 0.1000\n",
      "epoch = 4 loss = 0.106, accuracy = 96.368%, val_loss = 0.574, val_accuracy = 84.600% & LR: 0.1000\n",
      "epoch = 5 loss = 0.100, accuracy = 96.518%, val_loss = 0.622, val_accuracy = 83.030% & LR: 0.0100\n",
      "epoch = 6 loss = 0.028, accuracy = 99.230%, val_loss = 0.421, val_accuracy = 88.190% & LR: 0.0100\n",
      "epoch = 7 loss = 0.008, accuracy = 99.908%, val_loss = 0.424, val_accuracy = 88.400% & LR: 0.0100\n",
      "epoch = 8 loss = 0.005, accuracy = 99.968%, val_loss = 0.427, val_accuracy = 88.520% & LR: 0.0100\n",
      "epoch = 9 loss = 0.004, accuracy = 99.986%, val_loss = 0.434, val_accuracy = 88.470% & LR: 0.0100\n",
      "epoch = 10 loss = 0.003, accuracy = 99.992%, val_loss = 0.436, val_accuracy = 88.510% & LR: 0.0010\n",
      "epoch = 11 loss = 0.002, accuracy = 100.000%, val_loss = 0.438, val_accuracy = 88.440% & LR: 0.0010\n",
      "epoch = 12 loss = 0.002, accuracy = 100.000%, val_loss = 0.438, val_accuracy = 88.520% & LR: 0.0010\n",
      "Post fine-tuning: Global sparsity = 59.090% & val_accuracy = 88.520%\n",
      "\n",
      "Pruning and Finetuning 5/21\n",
      "Pruning...\n",
      "Global sparsity = 67.275% & val_accuracy = 88.520%\n",
      "\n",
      "Fine-tuning...\n",
      "Pre fine-tuning: val_loss = 0.438 & val_accuracy = 88.520%\n",
      "epoch = 1 loss = 0.049, accuracy = 98.366%, val_loss = 0.702, val_accuracy = 81.090% & LR: 0.1000\n",
      "epoch = 2 loss = 0.132, accuracy = 95.380%, val_loss = 0.621, val_accuracy = 83.420% & LR: 0.1000\n",
      "epoch = 3 loss = 0.105, accuracy = 96.388%, val_loss = 0.672, val_accuracy = 82.780% & LR: 0.1000\n",
      "epoch = 4 loss = 0.094, accuracy = 96.742%, val_loss = 0.632, val_accuracy = 82.740% & LR: 0.1000\n",
      "epoch = 5 loss = 0.099, accuracy = 96.540%, val_loss = 0.604, val_accuracy = 84.580% & LR: 0.0100\n",
      "epoch = 6 loss = 0.026, accuracy = 99.252%, val_loss = 0.418, val_accuracy = 88.710% & LR: 0.0100\n",
      "epoch = 7 loss = 0.007, accuracy = 99.948%, val_loss = 0.423, val_accuracy = 88.870% & LR: 0.0100\n",
      "epoch = 8 loss = 0.004, accuracy = 99.988%, val_loss = 0.421, val_accuracy = 88.860% & LR: 0.0100\n",
      "epoch = 9 loss = 0.003, accuracy = 99.990%, val_loss = 0.435, val_accuracy = 89.010% & LR: 0.0100\n",
      "epoch = 10 loss = 0.003, accuracy = 99.996%, val_loss = 0.440, val_accuracy = 88.970% & LR: 0.0010\n",
      "epoch = 11 loss = 0.002, accuracy = 99.994%, val_loss = 0.439, val_accuracy = 88.980% & LR: 0.0010\n",
      "epoch = 12 loss = 0.002, accuracy = 100.000%, val_loss = 0.433, val_accuracy = 89.050% & LR: 0.0010\n",
      "Post fine-tuning: Global sparsity = 67.275% & val_accuracy = 89.050%\n",
      "\n",
      "Pruning and Finetuning 6/21\n",
      "Pruning...\n",
      "Global sparsity = 73.831% & val_accuracy = 89.040%\n",
      "\n",
      "Fine-tuning...\n",
      "Pre fine-tuning: val_loss = 0.433 & val_accuracy = 89.040%\n",
      "epoch = 1 loss = 0.033, accuracy = 98.886%, val_loss = 0.714, val_accuracy = 81.180% & LR: 0.1000\n",
      "epoch = 2 loss = 0.125, accuracy = 95.672%, val_loss = 0.723, val_accuracy = 81.170% & LR: 0.1000\n",
      "epoch = 3 loss = 0.101, accuracy = 96.426%, val_loss = 0.841, val_accuracy = 79.230% & LR: 0.1000\n",
      "epoch = 4 loss = 0.095, accuracy = 96.788%, val_loss = 0.617, val_accuracy = 83.540% & LR: 0.1000\n",
      "epoch = 5 loss = 0.087, accuracy = 96.916%, val_loss = 0.657, val_accuracy = 82.490% & LR: 0.0100\n",
      "epoch = 6 loss = 0.024, accuracy = 99.350%, val_loss = 0.429, val_accuracy = 88.580% & LR: 0.0100\n",
      "epoch = 7 loss = 0.006, accuracy = 99.948%, val_loss = 0.434, val_accuracy = 88.770% & LR: 0.0100\n",
      "epoch = 8 loss = 0.004, accuracy = 99.980%, val_loss = 0.429, val_accuracy = 88.990% & LR: 0.0100\n",
      "epoch = 9 loss = 0.003, accuracy = 99.992%, val_loss = 0.438, val_accuracy = 89.040% & LR: 0.0100\n",
      "epoch = 10 loss = 0.002, accuracy = 99.988%, val_loss = 0.438, val_accuracy = 89.070% & LR: 0.0010\n",
      "epoch = 11 loss = 0.002, accuracy = 99.994%, val_loss = 0.436, val_accuracy = 89.070% & LR: 0.0010\n",
      "epoch = 12 loss = 0.002, accuracy = 99.994%, val_loss = 0.433, val_accuracy = 89.160% & LR: 0.0010\n",
      "Post fine-tuning: Global sparsity = 73.831% & val_accuracy = 89.160%\n",
      "\n",
      "Pruning and Finetuning 7/21\n",
      "Pruning...\n",
      "Global sparsity = 79.076% & val_accuracy = 89.230%\n",
      "\n",
      "Fine-tuning...\n",
      "Pre fine-tuning: val_loss = 0.432 & val_accuracy = 89.230%\n",
      "epoch = 1 loss = 0.018, accuracy = 99.462%, val_loss = 0.938, val_accuracy = 79.370% & LR: 0.1000\n",
      "epoch = 2 loss = 0.123, accuracy = 95.812%, val_loss = 0.597, val_accuracy = 83.560% & LR: 0.1000\n",
      "epoch = 3 loss = 0.095, accuracy = 96.716%, val_loss = 0.508, val_accuracy = 85.720% & LR: 0.1000\n",
      "epoch = 4 loss = 0.085, accuracy = 97.124%, val_loss = 0.667, val_accuracy = 84.440% & LR: 0.1000\n",
      "epoch = 5 loss = 0.083, accuracy = 97.100%, val_loss = 0.606, val_accuracy = 84.940% & LR: 0.0100\n",
      "epoch = 6 loss = 0.022, accuracy = 99.390%, val_loss = 0.439, val_accuracy = 88.540% & LR: 0.0100\n",
      "epoch = 7 loss = 0.006, accuracy = 99.938%, val_loss = 0.433, val_accuracy = 88.810% & LR: 0.0100\n",
      "epoch = 8 loss = 0.004, accuracy = 99.994%, val_loss = 0.437, val_accuracy = 88.910% & LR: 0.0100\n",
      "epoch = 9 loss = 0.003, accuracy = 99.994%, val_loss = 0.438, val_accuracy = 88.880% & LR: 0.0100\n",
      "epoch = 10 loss = 0.002, accuracy = 99.994%, val_loss = 0.442, val_accuracy = 89.020% & LR: 0.0010\n",
      "epoch = 11 loss = 0.002, accuracy = 99.992%, val_loss = 0.442, val_accuracy = 89.110% & LR: 0.0010\n",
      "epoch = 12 loss = 0.002, accuracy = 99.998%, val_loss = 0.440, val_accuracy = 89.000% & LR: 0.0010\n",
      "Post fine-tuning: Global sparsity = 79.076% & val_accuracy = 89.000%\n",
      "\n",
      "Pruning and Finetuning 8/21\n",
      "Pruning...\n",
      "Global sparsity = 83.270% & val_accuracy = 89.000%\n",
      "\n",
      "Fine-tuning...\n",
      "Pre fine-tuning: val_loss = 0.437 & val_accuracy = 89.000%\n",
      "epoch = 1 loss = 0.004, accuracy = 99.954%, val_loss = 0.581, val_accuracy = 87.500% & LR: 0.1000\n",
      "epoch = 2 loss = 0.106, accuracy = 96.378%, val_loss = 0.583, val_accuracy = 83.990% & LR: 0.1000\n",
      "epoch = 3 loss = 0.089, accuracy = 96.968%, val_loss = 0.581, val_accuracy = 84.920% & LR: 0.1000\n",
      "epoch = 4 loss = 0.084, accuracy = 97.058%, val_loss = 0.623, val_accuracy = 84.230% & LR: 0.1000\n",
      "epoch = 5 loss = 0.080, accuracy = 97.220%, val_loss = 0.630, val_accuracy = 83.770% & LR: 0.0100\n",
      "epoch = 6 loss = 0.024, accuracy = 99.298%, val_loss = 0.440, val_accuracy = 87.890% & LR: 0.0100\n",
      "epoch = 7 loss = 0.006, accuracy = 99.944%, val_loss = 0.444, val_accuracy = 88.300% & LR: 0.0100\n",
      "epoch = 8 loss = 0.004, accuracy = 99.978%, val_loss = 0.450, val_accuracy = 88.350% & LR: 0.0100\n",
      "epoch = 9 loss = 0.003, accuracy = 99.986%, val_loss = 0.449, val_accuracy = 88.630% & LR: 0.0100\n",
      "epoch = 10 loss = 0.002, accuracy = 99.996%, val_loss = 0.445, val_accuracy = 88.650% & LR: 0.0010\n",
      "epoch = 11 loss = 0.002, accuracy = 99.996%, val_loss = 0.448, val_accuracy = 88.580% & LR: 0.0010\n",
      "epoch = 12 loss = 0.002, accuracy = 100.000%, val_loss = 0.446, val_accuracy = 88.730% & LR: 0.0010\n",
      "Post fine-tuning: Global sparsity = 83.270% & val_accuracy = 88.730%\n",
      "\n",
      "Pruning and Finetuning 9/21\n",
      "Pruning...\n",
      "Global sparsity = 86.626% & val_accuracy = 88.660%\n",
      "\n",
      "Fine-tuning...\n",
      "Pre fine-tuning: val_loss = 0.443 & val_accuracy = 88.660%\n",
      "epoch = 1 loss = 0.003, accuracy = 99.976%, val_loss = 0.512, val_accuracy = 88.440% & LR: 0.1000\n",
      "epoch = 2 loss = 0.045, accuracy = 98.520%, val_loss = 0.709, val_accuracy = 82.570% & LR: 0.1000\n",
      "epoch = 3 loss = 0.109, accuracy = 96.158%, val_loss = 0.530, val_accuracy = 85.200% & LR: 0.1000\n",
      "epoch = 4 loss = 0.088, accuracy = 96.852%, val_loss = 0.562, val_accuracy = 84.420% & LR: 0.1000\n",
      "epoch = 5 loss = 0.072, accuracy = 97.510%, val_loss = 0.658, val_accuracy = 83.980% & LR: 0.0100\n",
      "epoch = 6 loss = 0.022, accuracy = 99.416%, val_loss = 0.425, val_accuracy = 88.720% & LR: 0.0100\n",
      "epoch = 7 loss = 0.006, accuracy = 99.952%, val_loss = 0.426, val_accuracy = 89.020% & LR: 0.0100\n",
      "epoch = 8 loss = 0.003, accuracy = 99.992%, val_loss = 0.428, val_accuracy = 89.030% & LR: 0.0100\n",
      "epoch = 9 loss = 0.003, accuracy = 99.998%, val_loss = 0.432, val_accuracy = 89.120% & LR: 0.0100\n",
      "epoch = 10 loss = 0.002, accuracy = 99.998%, val_loss = 0.428, val_accuracy = 89.220% & LR: 0.0010\n",
      "epoch = 11 loss = 0.002, accuracy = 99.994%, val_loss = 0.432, val_accuracy = 89.180% & LR: 0.0010\n",
      "epoch = 12 loss = 0.002, accuracy = 99.998%, val_loss = 0.434, val_accuracy = 89.200% & LR: 0.0010\n",
      "Post fine-tuning: Global sparsity = 86.626% & val_accuracy = 89.200%\n",
      "\n",
      "Pruning and Finetuning 10/21\n",
      "Pruning...\n",
      "Global sparsity = 89.311% & val_accuracy = 89.210%\n",
      "\n",
      "Fine-tuning...\n",
      "Pre fine-tuning: val_loss = 0.428 & val_accuracy = 89.210%\n",
      "epoch = 1 loss = 0.003, accuracy = 99.968%, val_loss = 0.495, val_accuracy = 88.280% & LR: 0.1000\n",
      "epoch = 2 loss = 0.080, accuracy = 97.324%, val_loss = 0.654, val_accuracy = 84.090% & LR: 0.1000\n",
      "epoch = 3 loss = 0.091, accuracy = 96.866%, val_loss = 0.682, val_accuracy = 83.750% & LR: 0.1000\n",
      "epoch = 4 loss = 0.077, accuracy = 97.332%, val_loss = 0.538, val_accuracy = 85.210% & LR: 0.1000\n",
      "epoch = 5 loss = 0.069, accuracy = 97.588%, val_loss = 0.699, val_accuracy = 83.500% & LR: 0.0100\n",
      "epoch = 6 loss = 0.021, accuracy = 99.358%, val_loss = 0.452, val_accuracy = 88.410% & LR: 0.0100\n",
      "epoch = 7 loss = 0.006, accuracy = 99.946%, val_loss = 0.448, val_accuracy = 88.570% & LR: 0.0100\n",
      "epoch = 8 loss = 0.004, accuracy = 99.984%, val_loss = 0.455, val_accuracy = 88.780% & LR: 0.0100\n",
      "epoch = 9 loss = 0.003, accuracy = 99.990%, val_loss = 0.447, val_accuracy = 88.860% & LR: 0.0100\n",
      "epoch = 10 loss = 0.002, accuracy = 99.992%, val_loss = 0.452, val_accuracy = 88.930% & LR: 0.0010\n",
      "epoch = 11 loss = 0.002, accuracy = 99.998%, val_loss = 0.452, val_accuracy = 88.820% & LR: 0.0010\n",
      "epoch = 12 loss = 0.002, accuracy = 99.998%, val_loss = 0.456, val_accuracy = 88.850% & LR: 0.0010\n",
      "Post fine-tuning: Global sparsity = 89.311% & val_accuracy = 88.850%\n",
      "\n",
      "Pruning and Finetuning 11/21\n",
      "Pruning...\n",
      "Global sparsity = 91.459% & val_accuracy = 88.800%\n",
      "\n",
      "Fine-tuning...\n",
      "Pre fine-tuning: val_loss = 0.448 & val_accuracy = 88.800%\n",
      "epoch = 1 loss = 0.003, accuracy = 99.990%, val_loss = 0.473, val_accuracy = 88.750% & LR: 0.1000\n",
      "epoch = 2 loss = 0.009, accuracy = 99.782%, val_loss = 0.656, val_accuracy = 84.740% & LR: 0.1000\n",
      "epoch = 3 loss = 0.120, accuracy = 95.826%, val_loss = 0.672, val_accuracy = 83.350% & LR: 0.1000\n",
      "epoch = 4 loss = 0.085, accuracy = 97.100%, val_loss = 0.683, val_accuracy = 83.100% & LR: 0.1000\n",
      "epoch = 5 loss = 0.072, accuracy = 97.526%, val_loss = 0.639, val_accuracy = 83.890% & LR: 0.0100\n",
      "epoch = 6 loss = 0.025, accuracy = 99.262%, val_loss = 0.435, val_accuracy = 88.480% & LR: 0.0100\n",
      "epoch = 7 loss = 0.007, accuracy = 99.918%, val_loss = 0.432, val_accuracy = 88.790% & LR: 0.0100\n",
      "epoch = 8 loss = 0.004, accuracy = 99.966%, val_loss = 0.444, val_accuracy = 88.690% & LR: 0.0100\n",
      "epoch = 9 loss = 0.003, accuracy = 99.982%, val_loss = 0.442, val_accuracy = 88.910% & LR: 0.0100\n",
      "epoch = 10 loss = 0.002, accuracy = 99.992%, val_loss = 0.442, val_accuracy = 88.870% & LR: 0.0010\n",
      "epoch = 11 loss = 0.002, accuracy = 99.998%, val_loss = 0.446, val_accuracy = 88.840% & LR: 0.0010\n",
      "epoch = 12 loss = 0.002, accuracy = 99.998%, val_loss = 0.443, val_accuracy = 88.930% & LR: 0.0010\n",
      "Post fine-tuning: Global sparsity = 91.459% & val_accuracy = 88.930%\n",
      "\n",
      "Pruning and Finetuning 12/21\n",
      "Pruning...\n",
      "Global sparsity = 93.177% & val_accuracy = 88.860%\n",
      "\n",
      "Fine-tuning...\n",
      "Pre fine-tuning: val_loss = 0.434 & val_accuracy = 88.860%\n",
      "epoch = 1 loss = 0.003, accuracy = 99.986%, val_loss = 0.486, val_accuracy = 88.670% & LR: 0.1000\n",
      "epoch = 2 loss = 0.044, accuracy = 98.564%, val_loss = 0.686, val_accuracy = 82.480% & LR: 0.1000\n",
      "epoch = 3 loss = 0.101, accuracy = 96.464%, val_loss = 0.686, val_accuracy = 82.930% & LR: 0.1000\n",
      "epoch = 4 loss = 0.076, accuracy = 97.324%, val_loss = 0.591, val_accuracy = 84.450% & LR: 0.1000\n",
      "epoch = 5 loss = 0.070, accuracy = 97.552%, val_loss = 0.654, val_accuracy = 84.180% & LR: 0.0100\n",
      "epoch = 6 loss = 0.018, accuracy = 99.500%, val_loss = 0.470, val_accuracy = 88.370% & LR: 0.0100\n",
      "epoch = 7 loss = 0.006, accuracy = 99.936%, val_loss = 0.467, val_accuracy = 88.500% & LR: 0.0100\n",
      "epoch = 8 loss = 0.003, accuracy = 99.986%, val_loss = 0.459, val_accuracy = 88.700% & LR: 0.0100\n",
      "epoch = 9 loss = 0.003, accuracy = 99.994%, val_loss = 0.465, val_accuracy = 88.700% & LR: 0.0100\n",
      "epoch = 10 loss = 0.002, accuracy = 100.000%, val_loss = 0.469, val_accuracy = 88.830% & LR: 0.0010\n",
      "epoch = 11 loss = 0.002, accuracy = 99.996%, val_loss = 0.463, val_accuracy = 88.830% & LR: 0.0010\n",
      "epoch = 12 loss = 0.002, accuracy = 99.994%, val_loss = 0.467, val_accuracy = 88.860% & LR: 0.0010\n",
      "Post fine-tuning: Global sparsity = 93.177% & val_accuracy = 88.860%\n",
      "\n",
      "Pruning and Finetuning 13/21\n",
      "Pruning...\n",
      "Global sparsity = 94.551% & val_accuracy = 88.380%\n",
      "\n",
      "Fine-tuning...\n",
      "Pre fine-tuning: val_loss = 0.465 & val_accuracy = 88.380%\n",
      "epoch = 1 loss = 0.009, accuracy = 99.758%, val_loss = 0.615, val_accuracy = 86.060% & LR: 0.1000\n",
      "epoch = 2 loss = 0.083, accuracy = 97.202%, val_loss = 0.660, val_accuracy = 82.780% & LR: 0.1000\n",
      "epoch = 3 loss = 0.073, accuracy = 97.514%, val_loss = 0.690, val_accuracy = 83.880% & LR: 0.1000\n",
      "epoch = 4 loss = 0.067, accuracy = 97.764%, val_loss = 0.634, val_accuracy = 84.300% & LR: 0.1000\n",
      "epoch = 5 loss = 0.060, accuracy = 97.978%, val_loss = 0.700, val_accuracy = 83.410% & LR: 0.0100\n",
      "epoch = 6 loss = 0.018, accuracy = 99.506%, val_loss = 0.465, val_accuracy = 88.210% & LR: 0.0100\n",
      "epoch = 7 loss = 0.005, accuracy = 99.950%, val_loss = 0.465, val_accuracy = 88.270% & LR: 0.0100\n",
      "epoch = 8 loss = 0.004, accuracy = 99.974%, val_loss = 0.464, val_accuracy = 88.560% & LR: 0.0100\n",
      "epoch = 9 loss = 0.003, accuracy = 99.992%, val_loss = 0.463, val_accuracy = 88.490% & LR: 0.0100\n",
      "epoch = 10 loss = 0.002, accuracy = 99.996%, val_loss = 0.467, val_accuracy = 88.600% & LR: 0.0010\n",
      "epoch = 11 loss = 0.002, accuracy = 99.990%, val_loss = 0.467, val_accuracy = 88.700% & LR: 0.0010\n",
      "epoch = 12 loss = 0.002, accuracy = 99.992%, val_loss = 0.474, val_accuracy = 88.580% & LR: 0.0010\n",
      "Post fine-tuning: Global sparsity = 94.551% & val_accuracy = 88.580%\n",
      "\n",
      "Pruning and Finetuning 14/21\n",
      "Pruning...\n",
      "Global sparsity = 95.650% & val_accuracy = 88.320%\n",
      "\n",
      "Fine-tuning...\n",
      "Pre fine-tuning: val_loss = 0.464 & val_accuracy = 88.320%\n",
      "epoch = 1 loss = 0.004, accuracy = 99.958%, val_loss = 0.612, val_accuracy = 86.740% & LR: 0.1000\n",
      "epoch = 2 loss = 0.050, accuracy = 98.312%, val_loss = 0.629, val_accuracy = 83.630% & LR: 0.1000\n",
      "epoch = 3 loss = 0.087, accuracy = 96.968%, val_loss = 0.609, val_accuracy = 84.680% & LR: 0.1000\n",
      "epoch = 4 loss = 0.068, accuracy = 97.672%, val_loss = 0.604, val_accuracy = 84.680% & LR: 0.1000\n",
      "epoch = 5 loss = 0.060, accuracy = 98.008%, val_loss = 0.794, val_accuracy = 80.840% & LR: 0.0100\n",
      "epoch = 6 loss = 0.019, accuracy = 99.468%, val_loss = 0.452, val_accuracy = 88.400% & LR: 0.0100\n",
      "epoch = 7 loss = 0.006, accuracy = 99.930%, val_loss = 0.451, val_accuracy = 88.670% & LR: 0.0100\n",
      "epoch = 8 loss = 0.004, accuracy = 99.978%, val_loss = 0.452, val_accuracy = 88.940% & LR: 0.0100\n",
      "epoch = 9 loss = 0.003, accuracy = 99.988%, val_loss = 0.452, val_accuracy = 88.800% & LR: 0.0100\n",
      "epoch = 10 loss = 0.002, accuracy = 99.992%, val_loss = 0.445, val_accuracy = 89.030% & LR: 0.0010\n",
      "epoch = 11 loss = 0.002, accuracy = 99.992%, val_loss = 0.449, val_accuracy = 88.850% & LR: 0.0010\n",
      "epoch = 12 loss = 0.002, accuracy = 99.996%, val_loss = 0.452, val_accuracy = 89.030% & LR: 0.0010\n",
      "Post fine-tuning: Global sparsity = 95.650% & val_accuracy = 89.030%\n",
      "\n",
      "Pruning and Finetuning 15/21\n",
      "Pruning...\n",
      "Global sparsity = 96.528% & val_accuracy = 88.780%\n",
      "\n",
      "Fine-tuning...\n",
      "Pre fine-tuning: val_loss = 0.446 & val_accuracy = 88.780%\n",
      "epoch = 1 loss = 0.021, accuracy = 99.336%, val_loss = 0.683, val_accuracy = 83.270% & LR: 0.1000\n",
      "epoch = 2 loss = 0.088, accuracy = 96.948%, val_loss = 0.771, val_accuracy = 82.340% & LR: 0.1000\n",
      "epoch = 3 loss = 0.069, accuracy = 97.658%, val_loss = 0.704, val_accuracy = 83.470% & LR: 0.1000\n",
      "epoch = 4 loss = 0.072, accuracy = 97.508%, val_loss = 0.608, val_accuracy = 84.530% & LR: 0.1000\n",
      "epoch = 5 loss = 0.061, accuracy = 97.904%, val_loss = 0.660, val_accuracy = 84.250% & LR: 0.0100\n",
      "epoch = 6 loss = 0.020, accuracy = 99.414%, val_loss = 0.462, val_accuracy = 88.650% & LR: 0.0100\n",
      "epoch = 7 loss = 0.006, accuracy = 99.912%, val_loss = 0.453, val_accuracy = 88.810% & LR: 0.0100\n",
      "epoch = 8 loss = 0.004, accuracy = 99.966%, val_loss = 0.461, val_accuracy = 88.890% & LR: 0.0100\n",
      "epoch = 9 loss = 0.003, accuracy = 99.980%, val_loss = 0.461, val_accuracy = 88.860% & LR: 0.0100\n",
      "epoch = 10 loss = 0.003, accuracy = 99.994%, val_loss = 0.461, val_accuracy = 89.130% & LR: 0.0010\n",
      "epoch = 11 loss = 0.002, accuracy = 99.996%, val_loss = 0.460, val_accuracy = 88.960% & LR: 0.0010\n",
      "epoch = 12 loss = 0.002, accuracy = 99.996%, val_loss = 0.458, val_accuracy = 89.050% & LR: 0.0010\n",
      "Post fine-tuning: Global sparsity = 96.528% & val_accuracy = 89.050%\n",
      "\n",
      "Pruning and Finetuning 16/21\n",
      "Pruning...\n",
      "Global sparsity = 97.230% & val_accuracy = 88.810%\n",
      "\n",
      "Fine-tuning...\n",
      "Pre fine-tuning: val_loss = 0.451 & val_accuracy = 88.810%\n",
      "epoch = 1 loss = 0.017, accuracy = 99.506%, val_loss = 0.750, val_accuracy = 83.770% & LR: 0.1000\n",
      "epoch = 2 loss = 0.086, accuracy = 96.962%, val_loss = 0.692, val_accuracy = 83.890% & LR: 0.1000\n",
      "epoch = 3 loss = 0.067, accuracy = 97.702%, val_loss = 0.780, val_accuracy = 82.230% & LR: 0.1000\n",
      "epoch = 4 loss = 0.070, accuracy = 97.610%, val_loss = 0.648, val_accuracy = 84.700% & LR: 0.1000\n",
      "epoch = 5 loss = 0.055, accuracy = 98.172%, val_loss = 0.620, val_accuracy = 85.120% & LR: 0.0100\n",
      "epoch = 6 loss = 0.020, accuracy = 99.418%, val_loss = 0.465, val_accuracy = 88.510% & LR: 0.0100\n",
      "epoch = 7 loss = 0.006, accuracy = 99.892%, val_loss = 0.456, val_accuracy = 88.850% & LR: 0.0100\n",
      "epoch = 8 loss = 0.004, accuracy = 99.968%, val_loss = 0.458, val_accuracy = 88.910% & LR: 0.0100\n",
      "epoch = 9 loss = 0.003, accuracy = 99.990%, val_loss = 0.461, val_accuracy = 88.900% & LR: 0.0100\n",
      "epoch = 10 loss = 0.003, accuracy = 99.992%, val_loss = 0.459, val_accuracy = 88.940% & LR: 0.0010\n",
      "epoch = 11 loss = 0.002, accuracy = 99.988%, val_loss = 0.461, val_accuracy = 88.930% & LR: 0.0010\n",
      "epoch = 12 loss = 0.002, accuracy = 99.994%, val_loss = 0.468, val_accuracy = 88.960% & LR: 0.0010\n",
      "Post fine-tuning: Global sparsity = 97.230% & val_accuracy = 88.960%\n",
      "\n",
      "Pruning and Finetuning 17/21\n",
      "Pruning...\n",
      "Global sparsity = 97.791% & val_accuracy = 88.040%\n",
      "\n",
      "Fine-tuning...\n",
      "Pre fine-tuning: val_loss = 0.464 & val_accuracy = 88.040%\n",
      "epoch = 1 loss = 0.032, accuracy = 98.978%, val_loss = 0.737, val_accuracy = 83.530% & LR: 0.1000\n",
      "epoch = 2 loss = 0.091, accuracy = 96.808%, val_loss = 0.627, val_accuracy = 83.870% & LR: 0.1000\n",
      "epoch = 3 loss = 0.078, accuracy = 97.348%, val_loss = 0.590, val_accuracy = 85.740% & LR: 0.1000\n",
      "epoch = 4 loss = 0.065, accuracy = 97.676%, val_loss = 0.674, val_accuracy = 83.870% & LR: 0.1000\n",
      "epoch = 5 loss = 0.068, accuracy = 97.604%, val_loss = 0.603, val_accuracy = 85.060% & LR: 0.0100\n",
      "epoch = 6 loss = 0.017, accuracy = 99.582%, val_loss = 0.455, val_accuracy = 88.630% & LR: 0.0100\n",
      "epoch = 7 loss = 0.006, accuracy = 99.932%, val_loss = 0.450, val_accuracy = 88.760% & LR: 0.0100\n",
      "epoch = 8 loss = 0.005, accuracy = 99.954%, val_loss = 0.456, val_accuracy = 88.640% & LR: 0.0100\n",
      "epoch = 9 loss = 0.004, accuracy = 99.994%, val_loss = 0.462, val_accuracy = 88.530% & LR: 0.0100\n",
      "epoch = 10 loss = 0.003, accuracy = 99.986%, val_loss = 0.455, val_accuracy = 88.860% & LR: 0.0010\n",
      "epoch = 11 loss = 0.003, accuracy = 99.992%, val_loss = 0.456, val_accuracy = 88.740% & LR: 0.0010\n",
      "epoch = 12 loss = 0.003, accuracy = 99.990%, val_loss = 0.457, val_accuracy = 88.800% & LR: 0.0010\n",
      "Post fine-tuning: Global sparsity = 97.791% & val_accuracy = 88.800%\n",
      "\n",
      "Pruning and Finetuning 18/21\n",
      "Pruning...\n",
      "Global sparsity = 98.237% & val_accuracy = 88.320%\n",
      "\n",
      "Fine-tuning...\n",
      "Pre fine-tuning: val_loss = 0.443 & val_accuracy = 88.320%\n",
      "epoch = 1 loss = 0.043, accuracy = 98.508%, val_loss = 0.664, val_accuracy = 83.840% & LR: 0.1000\n",
      "epoch = 2 loss = 0.090, accuracy = 96.868%, val_loss = 0.760, val_accuracy = 81.380% & LR: 0.1000\n",
      "epoch = 3 loss = 0.083, accuracy = 97.136%, val_loss = 0.602, val_accuracy = 85.020% & LR: 0.1000\n",
      "epoch = 4 loss = 0.067, accuracy = 97.666%, val_loss = 0.561, val_accuracy = 85.570% & LR: 0.1000\n",
      "epoch = 5 loss = 0.065, accuracy = 97.778%, val_loss = 0.598, val_accuracy = 84.990% & LR: 0.0100\n",
      "epoch = 6 loss = 0.024, accuracy = 99.298%, val_loss = 0.451, val_accuracy = 88.260% & LR: 0.0100\n",
      "epoch = 7 loss = 0.008, accuracy = 99.886%, val_loss = 0.456, val_accuracy = 88.660% & LR: 0.0100\n",
      "epoch = 8 loss = 0.005, accuracy = 99.948%, val_loss = 0.457, val_accuracy = 88.740% & LR: 0.0100\n",
      "epoch = 9 loss = 0.004, accuracy = 99.984%, val_loss = 0.465, val_accuracy = 88.790% & LR: 0.0100\n",
      "epoch = 10 loss = 0.004, accuracy = 99.976%, val_loss = 0.465, val_accuracy = 88.960% & LR: 0.0010\n",
      "epoch = 11 loss = 0.003, accuracy = 99.978%, val_loss = 0.463, val_accuracy = 88.830% & LR: 0.0010\n",
      "epoch = 12 loss = 0.003, accuracy = 99.990%, val_loss = 0.463, val_accuracy = 89.020% & LR: 0.0010\n",
      "Post fine-tuning: Global sparsity = 98.237% & val_accuracy = 89.020%\n",
      "\n",
      "Pruning and Finetuning 19/21\n",
      "Pruning...\n",
      "Global sparsity = 98.593% & val_accuracy = 87.880%\n",
      "\n",
      "Fine-tuning...\n",
      "Pre fine-tuning: val_loss = 0.471 & val_accuracy = 87.880%\n",
      "epoch = 1 loss = 0.057, accuracy = 98.158%, val_loss = 0.602, val_accuracy = 84.380% & LR: 0.1000\n",
      "epoch = 2 loss = 0.093, accuracy = 96.736%, val_loss = 0.537, val_accuracy = 85.770% & LR: 0.1000\n",
      "epoch = 3 loss = 0.082, accuracy = 97.142%, val_loss = 0.552, val_accuracy = 85.650% & LR: 0.1000\n",
      "epoch = 4 loss = 0.074, accuracy = 97.456%, val_loss = 0.654, val_accuracy = 83.750% & LR: 0.1000\n",
      "epoch = 5 loss = 0.078, accuracy = 97.316%, val_loss = 0.650, val_accuracy = 83.600% & LR: 0.0100\n",
      "epoch = 6 loss = 0.027, accuracy = 99.196%, val_loss = 0.454, val_accuracy = 88.270% & LR: 0.0100\n",
      "epoch = 7 loss = 0.010, accuracy = 99.854%, val_loss = 0.451, val_accuracy = 88.510% & LR: 0.0100\n",
      "epoch = 8 loss = 0.007, accuracy = 99.942%, val_loss = 0.456, val_accuracy = 88.640% & LR: 0.0100\n",
      "epoch = 9 loss = 0.005, accuracy = 99.960%, val_loss = 0.460, val_accuracy = 88.720% & LR: 0.0100\n",
      "epoch = 10 loss = 0.004, accuracy = 99.966%, val_loss = 0.460, val_accuracy = 88.720% & LR: 0.0010\n",
      "epoch = 11 loss = 0.004, accuracy = 99.986%, val_loss = 0.461, val_accuracy = 88.820% & LR: 0.0010\n",
      "epoch = 12 loss = 0.003, accuracy = 99.990%, val_loss = 0.462, val_accuracy = 88.740% & LR: 0.0010\n",
      "Post fine-tuning: Global sparsity = 98.593% & val_accuracy = 88.740%\n",
      "\n",
      "Pruning and Finetuning 20/21\n",
      "Pruning...\n",
      "Global sparsity = 98.877% & val_accuracy = 87.720%\n",
      "\n",
      "Fine-tuning...\n",
      "Pre fine-tuning: val_loss = 0.460 & val_accuracy = 87.720%\n",
      "epoch = 1 loss = 0.071, accuracy = 97.562%, val_loss = 0.632, val_accuracy = 84.280% & LR: 0.1000\n",
      "epoch = 2 loss = 0.099, accuracy = 96.538%, val_loss = 0.604, val_accuracy = 84.310% & LR: 0.1000\n",
      "epoch = 3 loss = 0.088, accuracy = 97.024%, val_loss = 0.577, val_accuracy = 85.510% & LR: 0.1000\n",
      "epoch = 4 loss = 0.082, accuracy = 97.172%, val_loss = 0.705, val_accuracy = 83.230% & LR: 0.1000\n",
      "epoch = 5 loss = 0.085, accuracy = 97.094%, val_loss = 0.581, val_accuracy = 85.730% & LR: 0.0100\n",
      "epoch = 6 loss = 0.031, accuracy = 99.086%, val_loss = 0.464, val_accuracy = 88.270% & LR: 0.0100\n",
      "epoch = 7 loss = 0.013, accuracy = 99.806%, val_loss = 0.469, val_accuracy = 88.320% & LR: 0.0100\n",
      "epoch = 8 loss = 0.008, accuracy = 99.918%, val_loss = 0.478, val_accuracy = 88.570% & LR: 0.0100\n",
      "epoch = 9 loss = 0.006, accuracy = 99.964%, val_loss = 0.479, val_accuracy = 88.540% & LR: 0.0100\n",
      "epoch = 10 loss = 0.005, accuracy = 99.962%, val_loss = 0.482, val_accuracy = 88.520% & LR: 0.0010\n",
      "epoch = 11 loss = 0.004, accuracy = 99.980%, val_loss = 0.478, val_accuracy = 88.600% & LR: 0.0010\n",
      "epoch = 12 loss = 0.004, accuracy = 99.982%, val_loss = 0.483, val_accuracy = 88.630% & LR: 0.0010\n",
      "Post fine-tuning: Global sparsity = 98.877% & val_accuracy = 88.630%\n",
      "\n",
      "Pruning and Finetuning 21/21\n",
      "Pruning...\n",
      "Global sparsity = 99.102% & val_accuracy = 87.160%\n",
      "\n",
      "Fine-tuning...\n",
      "Pre fine-tuning: val_loss = 0.479 & val_accuracy = 87.160%\n",
      "epoch = 1 loss = 0.080, accuracy = 97.246%, val_loss = 0.676, val_accuracy = 83.850% & LR: 0.1000\n",
      "epoch = 2 loss = 0.116, accuracy = 95.942%, val_loss = 0.581, val_accuracy = 85.010% & LR: 0.1000\n",
      "epoch = 3 loss = 0.097, accuracy = 96.602%, val_loss = 0.616, val_accuracy = 85.010% & LR: 0.1000\n",
      "epoch = 4 loss = 0.099, accuracy = 96.578%, val_loss = 0.621, val_accuracy = 84.270% & LR: 0.1000\n",
      "epoch = 5 loss = 0.098, accuracy = 96.556%, val_loss = 0.700, val_accuracy = 83.330% & LR: 0.0100\n",
      "epoch = 6 loss = 0.038, accuracy = 98.848%, val_loss = 0.447, val_accuracy = 88.430% & LR: 0.0100\n",
      "epoch = 7 loss = 0.015, accuracy = 99.740%, val_loss = 0.456, val_accuracy = 88.420% & LR: 0.0100\n",
      "epoch = 8 loss = 0.010, accuracy = 99.846%, val_loss = 0.460, val_accuracy = 88.560% & LR: 0.0100\n",
      "epoch = 9 loss = 0.008, accuracy = 99.916%, val_loss = 0.469, val_accuracy = 88.520% & LR: 0.0100\n",
      "epoch = 10 loss = 0.006, accuracy = 99.962%, val_loss = 0.472, val_accuracy = 88.450% & LR: 0.0010\n",
      "epoch = 11 loss = 0.005, accuracy = 99.964%, val_loss = 0.466, val_accuracy = 88.600% & LR: 0.0010\n",
      "epoch = 12 loss = 0.005, accuracy = 99.970%, val_loss = 0.477, val_accuracy = 88.590% & LR: 0.0010\n",
      "Post fine-tuning: Global sparsity = 99.102% & val_accuracy = 88.590%\n"
     ]
    }
   ],
   "source": [
    "# Perform iterative pruning and fine-tuning\n",
    "pruned_model = iterative_pruning_finetuning(\n",
    "        model = pruned_model, train_loader = train_loader,\n",
    "        test_loader = test_loader, device = device,\n",
    "        learning_rate = learning_rate, learning_rate_decay = learning_rate_decay,\n",
    "        l1_regularization_strength = l1_regularization_strength, l2_regularization_strength = l2_regularization_strength,\n",
    "        conv2d_prune_amount = 0.2, linear_prune_amount = 0.1,\n",
    "        num_iterations = 21, num_epochs_per_iteration = 12,\n",
    "        model_filename_prefix = model_filename_prefix, model_dir = model_dir,\n",
    "        grouped_pruning = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (layer1): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (shortcut): Sequential()\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (shortcut): Sequential()\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (shortcut): Sequential(\n",
       "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (shortcut): Sequential()\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (shortcut): Sequential(\n",
       "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (shortcut): Sequential()\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (shortcut): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (shortcut): Sequential()\n",
       "    )\n",
       "  )\n",
       "  (linear): Linear(in_features=512, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Apply pruned mask to the parameters/weights and remove the masks\n",
    "remove_parameters(model = pruned_model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the pruned model\n",
    "_, eval_accuracy = evaluate_model(\n",
    "    model = pruned_model, test_loader = test_loader,\n",
    "    device = device, criterion = None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global sparsity = 0.991 & val_accuracy = 0.886\n"
     ]
    }
   ],
   "source": [
    "# Measure the sparsity of the pruned model\n",
    "num_zeros, num_elements, sparsity = measure_global_sparsity(pruned_model)\n",
    "print(f\"Global sparsity = {sparsity:.3f} & val_accuracy = {eval_accuracy:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove pruning parameters\n",
    "final_model = remove_parameters(pruned_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the final model\n",
    "_, eval_accuracy = evaluate_model(\n",
    "    model = final_model, test_loader = test_loader,\n",
    "    device = device, criterion = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global sparsity = 99.122% & val_accuracy = 88.590%\n"
     ]
    }
   ],
   "source": [
    "# Measure the sparsity of the final model\n",
    "num_zeros, num_elements, sparsity = measure_global_sparsity(pruned_model)\n",
    "print(f\"Global sparsity = {sparsity * 100:.3f}% & val_accuracy = {eval_accuracy * 100:.3f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the final model\n",
    "torch.save(final_model.state_dict(), f\"ResNet18_trained_sparsity-{sparsity * 100:.3f}.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the final model for a sanity check\n",
    "trained_pruned_model = ResNet18()\n",
    "trained_pruned_model.load_state_dict(torch.load('ResNet18_trained_sparsity-99.122.pth'))\n",
    "\n",
    "# Move model to GPU (if available)\n",
    "trained_pruned_model.to(device)\n",
    "\n",
    "# Define cost function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(\n",
    "        trained_pruned_model.parameters(), lr = learning_rate,\n",
    "        momentum = 0.9, weight_decay = l2_regularization_strength\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the final model\n",
    "eval_loss, eval_accuracy = evaluate_model(\n",
    "    model = trained_pruned_model, test_loader=test_loader,\n",
    "    device = device, criterion = None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global sparsity = 99.122%, val_loss = 0.000 & val_accuracy = 88.590%\n"
     ]
    }
   ],
   "source": [
    "# Measure the sparsity of the final model\n",
    "num_zeros, num_elements, sparsity = measure_global_sparsity(trained_pruned_model)\n",
    "print(f\"Global sparsity = {sparsity * 100:.3f}%, val_loss = {eval_loss:.3f} & val_accuracy = {eval_accuracy * 100:.3f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the final accuracy above"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bonus task below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean activation: 0.244963139295578\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "def plot_weight_distribution(model, title):\n",
    "    weights = []\n",
    "    for name, param in model.named_parameters():\n",
    "        if 'weight' in name:\n",
    "            weights += list(param.cpu().detach().numpy().flatten())\n",
    "    plt.hist(weights, bins=100)\n",
    "    plt.title(title)\n",
    "    plt.show()\n",
    "    plt.close()  # Close the plot to free up memory\n",
    "\n",
    "# Move the model to CPU to free up GPU memory\n",
    "trained_pruned_model.to('cpu')\n",
    "\n",
    "# Plot the weight distribution for layers pre-pruning\n",
    "plot_weight_distribution(new_to_be_pruned_model, \"Weight distribution pre-pruning\")\n",
    "\n",
    "# Plot the weight distribution for layers post-pruning\n",
    "plot_weight_distribution(trained_pruned_model, \"Weight distribution post-pruning\")\n",
    "\n",
    "def check_activation_balance(model, dataloader):\n",
    "    model.eval()\n",
    "    activations = []\n",
    "    for inputs, _ in dataloader:\n",
    "        inputs = inputs.to('cpu')  # Move inputs to CPU to free up GPU memory\n",
    "        outputs = model(inputs)\n",
    "        activations.append(outputs.detach().numpy())\n",
    "    activations = np.concatenate(activations)\n",
    "    mean_activation = np.mean(activations)\n",
    "    print(f\"Mean activation: {mean_activation}\")\n",
    "\n",
    "# Check the balance of the activations when input is passed\n",
    "check_activation_balance(trained_pruned_model, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
